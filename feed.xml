<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <generator uri="http://jekyllrb.com" version="3.9.0">Jekyll</generator>
  
  
  <link href="https://dotkay.github.io/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://dotkay.github.io/" rel="alternate" type="text/html" hreflang="en" />
  <updated>2021-01-06T23:37:09+00:00</updated>
  <id>https://dotkay.github.io//</id>

  
    <title type="html">Quotidien</title>
  

  
    <subtitle>Learning by teaching</subtitle>
  

  

  
  
    <entry>
      
      <title type="html">TSLA joins S&amp;amp;P 500 →</title>
      
      <link href="https://dotkay.github.io/2020/12/24/tsla-spy/" rel="alternate" type="text/html" title="TSLA joins S&amp;P 500" />
      <published>2020-12-24T00:00:00+00:00</published>
      <updated>2020-12-24T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2020/12/24/tsla-spy</id>
      <content type="html" xml:base="https://dotkay.github.io/2020/12/24/tsla-spy/">&lt;p&gt;A week ago Tesla Motors (TSLA) joined the S&amp;amp;P 500 Index - the stock market index that keeps track of the performance of 500 largest companies listed in stock markets in the US. Overall TSLA has been very volatile - many argue that the volatility (risk) indicates the opportunies for Tesla. Now that we are towards the end of the year, a pandemic year, let’s see how the S&amp;amp;P 500 performed and how Tesla performed.&lt;/p&gt;

&lt;p&gt;A KDE plot of the adjusted closing values of S&amp;amp;P 500 Index as well as Tesla stock for the year (from January 1, 2020 until December 23, 2020) looks like the following. It clearly shows the spread.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;img_container&quot;&gt;
  &lt;center&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dotkay/data_science/master/plots/tsla_snp_kde_2020.png&quot; /&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;And in terms of the value of TSLA stock and S&amp;amp;P 500 Index, this is how they fared during this year:&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;img_container&quot;&gt;
  &lt;center&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dotkay/data_science/master/plots/tsla_snp_2020.png&quot; /&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;All the data was collected using pandas_datareader and the plots done using seaborn library.&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="energy" />
      
        <category term="electric" />
      
        <category term="S&amp;P 500" />
      
        <category term="TSLA" />
      

      

      
        <summary type="html">A week ago Tesla Motors (TSLA) joined the S&amp;amp;P 500 Index - the stock market index that keeps track of the performance of 500 largest companies listed in stock markets in the US. Overall TSLA has been very volatile - many argue that the volatility (risk) indicates the opportunies for Tesla. Now that we are towards the end of the year, a pandemic year, let’s see how the S&amp;amp;P 500 performed and how Tesla performed. A KDE plot of the adjusted closing values of S&amp;amp;P 500 Index as well as Tesla stock for the year (from January 1, 2020 until December 23, 2020) looks like the following. It clearly shows the spread. And in terms of the value of TSLA stock and S&amp;amp;P 500 Index, this is how they fared during this year: All the data was collected using pandas_datareader and the plots done using seaborn library.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Global Trends in Electric Vehicles →</title>
      
      <link href="https://dotkay.github.io/2020/06/06/evs/" rel="alternate" type="text/html" title="Global Trends in Electric Vehicles" />
      <published>2020-06-06T00:00:00+00:00</published>
      <updated>2020-06-06T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2020/06/06/evs</id>
      <content type="html" xml:base="https://dotkay.github.io/2020/06/06/evs/">&lt;p&gt;In an &lt;a href=&quot;https://dotkay.github.io/2020/06/01/covid-vs-coal/&quot;&gt;earlier post&lt;/a&gt;, we learnt something that we do not see everyday, even if we work in a coal mine, as the variety of energy and the consumption end points blind us from looking at the full picture. Today, we will look at some trends that we see all around us, all the time - Electric vehicles (EVs).&lt;/p&gt;

&lt;p&gt;For most of us, an &lt;em&gt;electric car&lt;/em&gt; immediately reminds us of Tesla - the innovative American automobile manufacturer that is to become the world’s most valuable automobile company very soon. Tesla is also the company that created an electric car revolution. Tesla’s success, in many ways, drove other automakers to accelerate their offering of all-electric products. We saw that the transition was not overnight. Many built hybrid vehicles (HEV), range-extended electric vehicles, plug-in hybrid vehicles (PHEV), before building all electric, or battery electric vehicles (BEV). However, if one is to guess which country on the planet has the most number of electric cars it would most likely be the US or EU, because of Tesla and the likes of VW or BMW (both of which make electric cars). Let’s see how the actual answer unfolds.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.iea.org/reports/global-ev-outlook-2020&quot;&gt;IEA’s global outlook&lt;/a&gt; and data show some impressive numbers. To quote from their report,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Only about 17 000 electric cars were on the world’s roads in 2010. By 2019, that number had swelled to 7.2 million, 47% of which were in The People’s Republic of China.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;img_container&quot;&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/images/energy/evs.PNG&quot; alt=&quot;EVs in the world&quot; class=&quot;img=responsive&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Further, despite purchase subsidies for electric cars were cut in many geographies (like tax credits in the US) and the resulting drop in electric car sales, the total number electric vehicles in China, EU and the US are still very impressive - 2.58 million BEVs in China compared to 0.88 million BEVs in the US and 0.97 million BEVs in the EU.&lt;/p&gt;

&lt;p&gt;One would start thinking what other industries are getting transformed along with the transformation of automotive industry. The implications of this transformation are huge touching several industries from service industry, retail and insurance. The analysis of the transformation itself would give fascninating insights. That would be the topic of a future post.&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="energy" />
      
        <category term="electric" />
      
        <category term="cars" />
      
        <category term="world" />
      
        <category term="EV" />
      

      

      
        <summary type="html">In an earlier post, we learnt something that we do not see everyday, even if we work in a coal mine, as the variety of energy and the consumption end points blind us from looking at the full picture. Today, we will look at some trends that we see all around us, all the time - Electric vehicles (EVs). For most of us, an electric car immediately reminds us of Tesla - the innovative American automobile manufacturer that is to become the world’s most valuable automobile company very soon. Tesla is also the company that created an electric car revolution. Tesla’s success, in many ways, drove other automakers to accelerate their offering of all-electric products. We saw that the transition was not overnight. Many built hybrid vehicles (HEV), range-extended electric vehicles, plug-in hybrid vehicles (PHEV), before building all electric, or battery electric vehicles (BEV). However, if one is to guess which country on the planet has the most number of electric cars it would most likely be the US or EU, because of Tesla and the likes of VW or BMW (both of which make electric cars). Let’s see how the actual answer unfolds. IEA’s global outlook and data show some impressive numbers. To quote from their report, Only about 17 000 electric cars were on the world’s roads in 2010. By 2019, that number had swelled to 7.2 million, 47% of which were in The People’s Republic of China. Further, despite purchase subsidies for electric cars were cut in many geographies (like tax credits in the US) and the resulting drop in electric car sales, the total number electric vehicles in China, EU and the US are still very impressive - 2.58 million BEVs in China compared to 0.88 million BEVs in the US and 0.97 million BEVs in the EU. One would start thinking what other industries are getting transformed along with the transformation of automotive industry. The implications of this transformation are huge touching several industries from service industry, retail and insurance. The analysis of the transformation itself would give fascninating insights. That would be the topic of a future post.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Covid vs Coal →</title>
      
      <link href="https://dotkay.github.io/2020/06/01/covid-vs-coal/" rel="alternate" type="text/html" title="Covid vs Coal" />
      <published>2020-06-01T00:00:00+00:00</published>
      <updated>2020-06-01T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2020/06/01/covid-vs-coal</id>
      <content type="html" xml:base="https://dotkay.github.io/2020/06/01/covid-vs-coal/">&lt;p&gt;I was listening to an interesting news program on renewable energy recently that made claims and projections about the current state and future of energy - primarily about renewable energy overtaking coal as the major source of energy. As a result of Covid, demand for electricity has fallen and as coal has become more and more expensive than renewable counterparts, coal based electricity is facing an uphill battle. Will coal survive the covid crisis, in developed countries, is yet to be seen.&lt;/p&gt;

&lt;p&gt;This prompted me to dig further into the data on energy production and consumption in the US. I was indeed surprised to see that coal based energy production is in fact decreasing in the US, and is decreasing drastically. I was surpised by two factors. First, I thought only under-developed or developing countries were the places where coal based energy was a major source, primarily due to the lack of infrastructure (like efficient transmission grids) and the cost of renewable energy (solar panels, wind turbines, etc.). Second, nuclear power production has flattened out somewhere in the last decade, and is now overtaken by renewable energy. With several nuclear power plants built over the decades, some of them dangerously &lt;a href=&quot;http://www.nbcnews.com/id/42103936/ns/world_news-asia_pacific/t/what-are-odds-us-nuke-plants-ranked-quake-risk/&quot;&gt;close to fault lines&lt;/a&gt;, I was expecting more energy to be generated by nuclear plants. It turned out that was not the case.&lt;/p&gt;

&lt;p&gt;Looking at the data, coal production is indeed decreasing and at such a rate that it is almost close to what it was in the 1950s. While renewable energy is all set to overtake coal based energy and experts predict 2020 to be the year for this to happen. In fact, renewable energy production has already overtaken nuclear energy.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;img_container&quot;&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/images/energy/coal_vs_renewable.PNG&quot; alt=&quot;Coal vs Renewable Energy&quot; class=&quot;img=responsive&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;While the above is certainly positive news, there are several other fossil fuels (natural gas, crude oil, etc.) just like there are several renewable energy sources (hydroelectric,  solar, wind, etc.). Looking at more details at the different sources of fossil fuels, although coal production has reduced, total fossil fuel production is still way more than renewable energy production as the following chart shows.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;img_container&quot;&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/images/energy/fossil_vs_renewable.PNG&quot; alt=&quot;Fossil Fuels vs Renewable Energy&quot; class=&quot;img=responsive&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Stay tuned for more insights into energy production and consumption in residential and transportation sectors.&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="energy" />
      
        <category term="coal" />
      
        <category term="renewable energy" />
      
        <category term="US" />
      

      

      
        <summary type="html">I was listening to an interesting news program on renewable energy recently that made claims and projections about the current state and future of energy - primarily about renewable energy overtaking coal as the major source of energy. As a result of Covid, demand for electricity has fallen and as coal has become more and more expensive than renewable counterparts, coal based electricity is facing an uphill battle. Will coal survive the covid crisis, in developed countries, is yet to be seen. This prompted me to dig further into the data on energy production and consumption in the US. I was indeed surprised to see that coal based energy production is in fact decreasing in the US, and is decreasing drastically. I was surpised by two factors. First, I thought only under-developed or developing countries were the places where coal based energy was a major source, primarily due to the lack of infrastructure (like efficient transmission grids) and the cost of renewable energy (solar panels, wind turbines, etc.). Second, nuclear power production has flattened out somewhere in the last decade, and is now overtaken by renewable energy. With several nuclear power plants built over the decades, some of them dangerously close to fault lines, I was expecting more energy to be generated by nuclear plants. It turned out that was not the case. Looking at the data, coal production is indeed decreasing and at such a rate that it is almost close to what it was in the 1950s. While renewable energy is all set to overtake coal based energy and experts predict 2020 to be the year for this to happen. In fact, renewable energy production has already overtaken nuclear energy. While the above is certainly positive news, there are several other fossil fuels (natural gas, crude oil, etc.) just like there are several renewable energy sources (hydroelectric, solar, wind, etc.). Looking at more details at the different sources of fossil fuels, although coal production has reduced, total fossil fuel production is still way more than renewable energy production as the following chart shows. Stay tuned for more insights into energy production and consumption in residential and transportation sectors.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Streaming vs Cinemas in a post COVID world →</title>
      
      <link href="https://dotkay.github.io/2020/05/05/streaming-vs-cinema-post-covid/" rel="alternate" type="text/html" title="Streaming vs Cinemas in a post COVID world" />
      <published>2020-05-05T00:00:00+00:00</published>
      <updated>2020-05-05T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2020/05/05/streaming-vs-cinema-post-covid</id>
      <content type="html" xml:base="https://dotkay.github.io/2020/05/05/streaming-vs-cinema-post-covid/">&lt;p&gt;Watching a movie with stunning visual special effects, sound effects is best done in cinema halls. The screens are wide, the hall geometry and &lt;a href=&quot;https://www.theaterseatstore.com/blog/movie-sound-systems&quot;&gt;sound technologies&lt;/a&gt; like &lt;a href=&quot;https://en.wikipedia.org/wiki/Surround_sound&quot;&gt;&lt;em&gt;surrond sound&lt;/em&gt;&lt;/a&gt; add to the experience. It is no surprise that movies like Jurrasic Park, Inception, Avengers, etc. are best watched on large screen, in cinemas. It is not just the story, it is the movie experience, besides the social aspect of being outside and the lights going down. US box office revenues were 11.32 billion USD in 2019 and 11.89 billion USD in 2018 (all time best).&lt;/p&gt;

&lt;p&gt;Lately, streaming has become very popular. It gives the convenience of watching the movie as and when one wanted, without having to drive to a cinema and at much lower price. A family of four can watch several movies in their living room for a monthly service fee of about $15, while a movie ticket would cost each of the family members as much. Added to this would be popcorn and soda. Netflix and lately almost every major studio is into streaming. Traditionally, movies were run in cinemas for about 90 days before getting released in digital format. But that 90 day “windowing” is coming under a lot of pressure with many streaming services deciding to release the movies right away in digital format.&lt;/p&gt;

&lt;p&gt;So, we have two interesting and opposing forces - cinema halls and streaming services. One provides the best experience while the other provides convenience and affordability. And then came the COVID pandemic. With cinema halls being the sort of place that by design invited a large gathering in an enclosed room, it provided the perfect recipe for a pandemic spread. Cinema halls are closed and people are stuck at home having not much of an entertainment - a perfect recipe for streaming services to be at their best to relieve those sheltering in place of their boredom.&lt;/p&gt;

&lt;p&gt;As if the scenario is not interesting enough, it was rumored that a popular movie streaming service - Amazon Prime Video made a bid for a popular cinema chain AMC. Although nothing of this is confirmed, the very thought process in analyzing this is interesting. What would be Amazon’s interest in AMC?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Amazon has a sizeable number of prime customers who get free shipping on goods and some deals on Whole Foods stores. Would Amazon give them monthly passes or subsidized tickets to watch movies in AMC?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Amazon Studios makes originals. Would those originals first be released in AMC and later streamed on Amazon Prime?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Would Amazon reserve AMC for the first few weeks, for movies with stellar visual and sound effects?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Would Amazon split the Studio products into TV shows like soaps for Amazon Prime and movies for AMC?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Would AMC become a Hollywood talent scouting arm for Amazon?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In all these, how would the pricing work? Amazon is known for maximizing efficiency and getting the best price for the end customer. Would it be able to replicate it in box office movies? If so, how? It is an interesting aspect waiting to be seen, if the rumours are true and if the deal goes through.&lt;/p&gt;

&lt;p&gt;Till then, relax on your couch and stream your favorite shows.&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="streaming" />
      
        <category term="cinema" />
      
        <category term="box office" />
      
        <category term="Netflix" />
      
        <category term="Amazon" />
      
        <category term="AMC" />
      

      

      
        <summary type="html">Watching a movie with stunning visual special effects, sound effects is best done in cinema halls. The screens are wide, the hall geometry and sound technologies like surrond sound add to the experience. It is no surprise that movies like Jurrasic Park, Inception, Avengers, etc. are best watched on large screen, in cinemas. It is not just the story, it is the movie experience, besides the social aspect of being outside and the lights going down. US box office revenues were 11.32 billion USD in 2019 and 11.89 billion USD in 2018 (all time best). Lately, streaming has become very popular. It gives the convenience of watching the movie as and when one wanted, without having to drive to a cinema and at much lower price. A family of four can watch several movies in their living room for a monthly service fee of about $15, while a movie ticket would cost each of the family members as much. Added to this would be popcorn and soda. Netflix and lately almost every major studio is into streaming. Traditionally, movies were run in cinemas for about 90 days before getting released in digital format. But that 90 day “windowing” is coming under a lot of pressure with many streaming services deciding to release the movies right away in digital format. So, we have two interesting and opposing forces - cinema halls and streaming services. One provides the best experience while the other provides convenience and affordability. And then came the COVID pandemic. With cinema halls being the sort of place that by design invited a large gathering in an enclosed room, it provided the perfect recipe for a pandemic spread. Cinema halls are closed and people are stuck at home having not much of an entertainment - a perfect recipe for streaming services to be at their best to relieve those sheltering in place of their boredom. As if the scenario is not interesting enough, it was rumored that a popular movie streaming service - Amazon Prime Video made a bid for a popular cinema chain AMC. Although nothing of this is confirmed, the very thought process in analyzing this is interesting. What would be Amazon’s interest in AMC? Amazon has a sizeable number of prime customers who get free shipping on goods and some deals on Whole Foods stores. Would Amazon give them monthly passes or subsidized tickets to watch movies in AMC? Amazon Studios makes originals. Would those originals first be released in AMC and later streamed on Amazon Prime? Would Amazon reserve AMC for the first few weeks, for movies with stellar visual and sound effects? Would Amazon split the Studio products into TV shows like soaps for Amazon Prime and movies for AMC? Would AMC become a Hollywood talent scouting arm for Amazon? In all these, how would the pricing work? Amazon is known for maximizing efficiency and getting the best price for the end customer. Would it be able to replicate it in box office movies? If so, how? It is an interesting aspect waiting to be seen, if the rumours are true and if the deal goes through. Till then, relax on your couch and stream your favorite shows.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Efficiency vs Flexibility →</title>
      
      <link href="https://dotkay.github.io/2020/04/01/efficiency-vs-flexibility/" rel="alternate" type="text/html" title="Efficiency vs Flexibility" />
      <published>2020-04-01T00:00:00+00:00</published>
      <updated>2020-04-01T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2020/04/01/efficiency-vs-flexibility</id>
      <content type="html" xml:base="https://dotkay.github.io/2020/04/01/efficiency-vs-flexibility/">&lt;p&gt;Despite the date of posting, this post isn’t a joke and is meant to provoke some thoughts on efficiency and flexibility.&lt;/p&gt;

&lt;p&gt;As a result of COVID-19 pandemic we saw the mad rush for toilet papers and other essentials that were getting swept off super-market shelves. Not just toilet papers, even face-masks and ventilators were in short supply at a time when they were most needed. Many consumer and semiconductor companies lowered their guidance due to disruptions in their supply chain. How did we get into a situation where so many industries - from toilet papers to iPhones were getting affected?&lt;/p&gt;

&lt;p&gt;The world over the many years got more globalized. American or Canadian products were not made in the US or Canada. They were made in places where it was cheaper and faster to make. Even &lt;a href=&quot;https://www.ft.com/content/360e2524-d71a-11e8-a854-33d6f82e62f8&quot;&gt;trash is sent to other countries&lt;/a&gt; in order to be recycled in a cost-effective manner. In short, global supply chain over the years shaped its goal into one that is more cost efficient rather than being flexible. This is not the first time companies are facing shocks. Not long ago, floods in Japan resulted in supply chain issues for automotive companies.&lt;/p&gt;

&lt;p&gt;Is this design for efficiency a problem? It definitely looks like, given what many countries went through as the COVID-19 pandemic stuck. Many companies were not able to reliably source their material and keep their assembly lines busy, as they were over-invested in the most (cost) efficient supply chains like in China. If instead the supply chains were designed for flexibility, the average marginal cost of a product “might be” (and just might be) a little higher but geography specific events would not throw the entire system out of gear. There is an emphasis on the uncertainity of the cost implications as it is not entirely clear at this point. For example, one could argue that, if the semiconductor industry had sourced from several geographies like China, India, Africa, South America, etc., it is very likely that the infrastructure for sustaining such supply chains would have developed in many such countries creating a healthy competition, thereby reducing the cost. And this applies to several industries, not just semiconductors.&lt;/p&gt;

&lt;p&gt;Have the corporates learnt a lesson now?. There was a similar talk after supply chain disruptions in Japan, but nothing materialized in the long run. Would this time be different? One has to wait and watch.&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="efficiency" />
      
        <category term="flexibility" />
      
        <category term="globalization" />
      
        <category term="supply chain" />
      

      

      
        <summary type="html">Despite the date of posting, this post isn’t a joke and is meant to provoke some thoughts on efficiency and flexibility. As a result of COVID-19 pandemic we saw the mad rush for toilet papers and other essentials that were getting swept off super-market shelves. Not just toilet papers, even face-masks and ventilators were in short supply at a time when they were most needed. Many consumer and semiconductor companies lowered their guidance due to disruptions in their supply chain. How did we get into a situation where so many industries - from toilet papers to iPhones were getting affected? The world over the many years got more globalized. American or Canadian products were not made in the US or Canada. They were made in places where it was cheaper and faster to make. Even trash is sent to other countries in order to be recycled in a cost-effective manner. In short, global supply chain over the years shaped its goal into one that is more cost efficient rather than being flexible. This is not the first time companies are facing shocks. Not long ago, floods in Japan resulted in supply chain issues for automotive companies. Is this design for efficiency a problem? It definitely looks like, given what many countries went through as the COVID-19 pandemic stuck. Many companies were not able to reliably source their material and keep their assembly lines busy, as they were over-invested in the most (cost) efficient supply chains like in China. If instead the supply chains were designed for flexibility, the average marginal cost of a product “might be” (and just might be) a little higher but geography specific events would not throw the entire system out of gear. There is an emphasis on the uncertainity of the cost implications as it is not entirely clear at this point. For example, one could argue that, if the semiconductor industry had sourced from several geographies like China, India, Africa, South America, etc., it is very likely that the infrastructure for sustaining such supply chains would have developed in many such countries creating a healthy competition, thereby reducing the cost. And this applies to several industries, not just semiconductors. Have the corporates learnt a lesson now?. There was a similar talk after supply chain disruptions in Japan, but nothing materialized in the long run. Would this time be different? One has to wait and watch.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">LinkedIn’s Business →</title>
      
      <link href="https://dotkay.github.io/2019/12/01/linkedin-business/" rel="alternate" type="text/html" title="LinkedIn's Business" />
      <published>2019-12-01T00:00:00+00:00</published>
      <updated>2019-12-01T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2019/12/01/linkedin-business</id>
      <content type="html" xml:base="https://dotkay.github.io/2019/12/01/linkedin-business/">&lt;p&gt;Lately, I have been reading about several businesses and trying to understand their product offerings, value proposition of the products, business model and how they came to be. With a natural inclination for technology products and a curiosity about startups and business models, this has been an enjoyable learning experience and I am hoping to share a lot of my learning through this medium. Let’s start with LinkedIn.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LinkedIn’s Vision&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Create economic opportunity for every member of the global workforce.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;dl&gt;
  &lt;dt&gt;I liked the simple and clear vision statement but was wondering why it mentions only &lt;em&gt;economic opportunity&lt;/em&gt; while LinkedIn’s products offer much more or could it be the case that all the benefits the products offer can be tied to economic opportunity? I started researching about what this term &lt;em&gt;economic opportunity&lt;/em&gt; entails and found &lt;a href=&quot;https://www.quora.com/How-are-economic-opportunities-defined&quot;&gt;this answer&lt;/a&gt; in Quora:&lt;/dt&gt;
  &lt;dt&gt;&lt;br /&gt;&lt;/dt&gt;
  &lt;dd&gt;
    &lt;p&gt;&lt;em&gt;When somebody is willing to pay you money for doing something that you are willing and able to do, that is an “economic opportunity”. It can be a small business idea or a job.If you can produce a product or provide a service that people are willing to pay for, that is a small business opportunity. If you have an ability or skill that an employer needs, that is a job opportunity.&lt;/em&gt;&lt;/p&gt;
  &lt;/dd&gt;
  &lt;dd&gt;
    &lt;p&gt;&lt;em&gt;Basically, an economic opportunity is the chance to do work that somebody is willing to pay you for. You don’t have to “like” the work. You just have to be able to competently do it. If you like your work, all the better for you. But we work to earn money that is paid by other people. The work we do is for other people’s benefit. The money they pay us is for our benefit. It is a reciprocal pay-earn, demand-supply economic relationship. They pay us money for supplying them what they want.&lt;/em&gt;&lt;/p&gt;
  &lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;I, however, feel that LinkedIn also provides knowledge opportunity (learning), business/marketing opportunity (sales leads) and career opportunity (jobs for professionals) and talent development (hiring solutions for recruiters) opportunity, etc. There might be some or some aspects of these on which you cannot really put a dollar value on in order for them to be called an &lt;em&gt;economic opportunity&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LinkedIn’s Mission&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The mission of LinkedIn is simple: connect the world’s professionals to make them more productive and successful.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Again, a short and crisp mission statement. But, again I believe that the main benefit is making professionals more skilled, equipped, informed, etc., rather than just productive.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LinkedIn’s Products&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;LinkedIn to many is just a networking site for professionals. But once you look at the suite of products it is much more than that. LinkedIn’s products are organized under four themes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hire&lt;/li&gt;
  &lt;li&gt;Market&lt;/li&gt;
  &lt;li&gt;Sell&lt;/li&gt;
  &lt;li&gt;Learn&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The various products under each of these themes are shown below:&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/images/products/linkedin_products.jpg&quot; alt=&quot;LinkedIn's Products&quot; class=&quot;img=responsive&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It is difficult to categorize each of the products into &lt;em&gt;advertisement-based&lt;/em&gt; or &lt;em&gt;subscription-based&lt;/em&gt; one as some of them overlap both business models. The &lt;em&gt;HIRE&lt;/em&gt; theme is mainly for human resources professionals to track, follow, and manage recruiting pipeline for their organizations. I believe this could be one of the most active products (along with learning) on the platform. The &lt;em&gt;MARKET&lt;/em&gt; theme helps in setting up marketing campaigns, reach out to potential resources for marketing purposes, set up custom pages, and serve advertisements on the pages and possibly through emails. Although it sounds like a lot of features, I believe they would have a very stiff competition from the likes of Google and Facebook. Although the advertisements would be more relevant to hiring and professional marketing, the eyeballs on these wouldn’t be as much as on Google search and Facebook feeds. However, with the volume of professionals in the network, hiring ads would get the best reach on this platform. The &lt;em&gt;SELL&lt;/em&gt; theme sounds like a specialized Salesforce platform.  The &lt;em&gt;LEARN&lt;/em&gt; theme is an upcoming Coursera. Although it may not offer a wide variety of specializations for now, with data from the &lt;em&gt;HIRE&lt;/em&gt; theme, it would be a more powerful medium for specialized skill development targeted at specific job roles in specific industries. We need to wait and watch how well Microsoft uses the data from one to better the offerings of another. Although LinkedIn membership is free, there is also a premium subscription which could be considered as a separate product in itself (creating significant revenue) and it is needed to use several of the other products, for example InMail.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LinkedIn’s business&lt;/strong&gt;&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;LinkedIn has become a significant business unit of Microsoft. According to a &lt;a href=&quot;https://www.businessofapps.com/data/linkedin-statistics/&quot;&gt;source&lt;/a&gt;&lt;/dt&gt;
  &lt;dt&gt;&lt;br /&gt;&lt;/dt&gt;
  &lt;dd&gt;
    &lt;p&gt;&lt;em&gt;In the 2019 fiscal year, LinkedIn brought in $6.8 billion worth of revenue, contributing to $38.1 billion of commercial cloud revenue for Microsoft, which in turn made up part of $126 billion total revenue.&lt;/em&gt;&lt;/p&gt;
  &lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;Further the numbers below from Microsoft’s earnings and LinkedIn newsroom validate the importance of LinkedIn and its potential.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/images/products/linkedin_fy20_q1.PNG&quot; alt=&quot;LinkedIn FY20 Q1&quot; class=&quot;img=responsive&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/products/linkedin_stats.PNG&quot; alt=&quot;LinkedIn impact&quot; class=&quot;img=responsive&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LinkedIn’s Opportunity&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/images/products/linkedin_worldwide.png&quot; alt=&quot;LinkedIn Stats&quot; class=&quot;img=responsive&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And that shows the opportunity for LinkedIn. Along with the above, GitHub - the world’s largest software development platform or the playground for developers was snapped up by Microsoft. This indicates a very huge potential. The data from &lt;em&gt;HIRE&lt;/em&gt; theme above combined with &lt;em&gt;LEARN&lt;/em&gt; theme and fueled by GitHub platform is a wonderful growth opportunity. GitHub + LinkedIn for developers would be Instagram for fashionistas and for businesses and recruiters this would be the Instagram for fashion brands seeking ambassadors and influencers. Probably some day very soon let me write about the opportunity for data science and AI in stitching all the above products together as one awesome fabric.&lt;/p&gt;

&lt;p&gt;Thats all for now!&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="technology" />
      
        <category term="products" />
      
        <category term="business" />
      
        <category term="LinkedIn" />
      

      

      
        <summary type="html">Lately, I have been reading about several businesses and trying to understand their product offerings, value proposition of the products, business model and how they came to be. With a natural inclination for technology products and a curiosity about startups and business models, this has been an enjoyable learning experience and I am hoping to share a lot of my learning through this medium. Let’s start with LinkedIn. LinkedIn’s Vision Create economic opportunity for every member of the global workforce. I liked the simple and clear vision statement but was wondering why it mentions only economic opportunity while LinkedIn’s products offer much more or could it be the case that all the benefits the products offer can be tied to economic opportunity? I started researching about what this term economic opportunity entails and found this answer in Quora: When somebody is willing to pay you money for doing something that you are willing and able to do, that is an “economic opportunity”. It can be a small business idea or a job.If you can produce a product or provide a service that people are willing to pay for, that is a small business opportunity. If you have an ability or skill that an employer needs, that is a job opportunity. Basically, an economic opportunity is the chance to do work that somebody is willing to pay you for. You don’t have to “like” the work. You just have to be able to competently do it. If you like your work, all the better for you. But we work to earn money that is paid by other people. The work we do is for other people’s benefit. The money they pay us is for our benefit. It is a reciprocal pay-earn, demand-supply economic relationship. They pay us money for supplying them what they want. I, however, feel that LinkedIn also provides knowledge opportunity (learning), business/marketing opportunity (sales leads) and career opportunity (jobs for professionals) and talent development (hiring solutions for recruiters) opportunity, etc. There might be some or some aspects of these on which you cannot really put a dollar value on in order for them to be called an economic opportunity. LinkedIn’s Mission The mission of LinkedIn is simple: connect the world’s professionals to make them more productive and successful. Again, a short and crisp mission statement. But, again I believe that the main benefit is making professionals more skilled, equipped, informed, etc., rather than just productive. LinkedIn’s Products LinkedIn to many is just a networking site for professionals. But once you look at the suite of products it is much more than that. LinkedIn’s products are organized under four themes: Hire Market Sell Learn The various products under each of these themes are shown below: It is difficult to categorize each of the products into advertisement-based or subscription-based one as some of them overlap both business models. The HIRE theme is mainly for human resources professionals to track, follow, and manage recruiting pipeline for their organizations. I believe this could be one of the most active products (along with learning) on the platform. The MARKET theme helps in setting up marketing campaigns, reach out to potential resources for marketing purposes, set up custom pages, and serve advertisements on the pages and possibly through emails. Although it sounds like a lot of features, I believe they would have a very stiff competition from the likes of Google and Facebook. Although the advertisements would be more relevant to hiring and professional marketing, the eyeballs on these wouldn’t be as much as on Google search and Facebook feeds. However, with the volume of professionals in the network, hiring ads would get the best reach on this platform. The SELL theme sounds like a specialized Salesforce platform. The LEARN theme is an upcoming Coursera. Although it may not offer a wide variety of specializations for now, with data from the HIRE theme, it would be a more powerful medium for specialized skill development targeted at specific job roles in specific industries. We need to wait and watch how well Microsoft uses the data from one to better the offerings of another. Although LinkedIn membership is free, there is also a premium subscription which could be considered as a separate product in itself (creating significant revenue) and it is needed to use several of the other products, for example InMail. LinkedIn’s business LinkedIn has become a significant business unit of Microsoft. According to a source In the 2019 fiscal year, LinkedIn brought in $6.8 billion worth of revenue, contributing to $38.1 billion of commercial cloud revenue for Microsoft, which in turn made up part of $126 billion total revenue. Further the numbers below from Microsoft’s earnings and LinkedIn newsroom validate the importance of LinkedIn and its potential. LinkedIn’s Opportunity And that shows the opportunity for LinkedIn. Along with the above, GitHub - the world’s largest software development platform or the playground for developers was snapped up by Microsoft. This indicates a very huge potential. The data from HIRE theme above combined with LEARN theme and fueled by GitHub platform is a wonderful growth opportunity. GitHub + LinkedIn for developers would be Instagram for fashionistas and for businesses and recruiters this would be the Instagram for fashion brands seeking ambassadors and influencers. Probably some day very soon let me write about the opportunity for data science and AI in stitching all the above products together as one awesome fabric. Thats all for now!</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">The Magic Money Tree →</title>
      
      <link href="https://dotkay.github.io/2019/07/01/mmt/" rel="alternate" type="text/html" title="The Magic Money Tree" />
      <published>2019-07-01T00:00:00+00:00</published>
      <updated>2019-07-01T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2019/07/01/mmt</id>
      <content type="html" xml:base="https://dotkay.github.io/2019/07/01/mmt/">&lt;p&gt;As people who know me understand, I read articles and listen to podcasts on a variety of topics ranging from technology, social science, society, economics, etc. Economics is one of my favourites, as it is very relatable to our day to day lives, besides involving mathematical modelling (which, for the same reasons as Deep Learning techniques of today, can only be close to a very good approximation but never accurate). While listening to BBC’s Business Daily podcasts, I stumbled upon this episode on Modern Monetary Theory. The title of the podcast - “Magic Money Tree” caught my attention and it turned out to be an interesting take on a proposal by one of the former Hedge Fund manager about central banks being able to print more money when needed. I did have this idea when I was a kid before I realized inflation and value of goods and how they are tied to abundance of ciculation of money, interest rates and consumer spending. I am not an economist but I am worried how this could lead to powerful economies manipulating their inflation thereby leading to disastrous consequences in parts of the world whose currencies are not global trade currencies.&lt;/p&gt;

&lt;p&gt;For those interested in listening to the episode, you can do it here:&lt;/p&gt;
&lt;audio controls=&quot;&quot;&gt;
&lt;source src=&quot;http://open.live.bbc.co.uk/mediaselector/6/redir/version/2.0/mediaset/audio-nondrm-download-low/proto/http/vpid/p079cpnd.mp3&quot; /&gt; 
&lt;/audio&gt;

&lt;p&gt;Are there wonderful teachers among expert economists who can
help me understand?&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="Money" />
      
        <category term="Monetary Policy" />
      

      

      
        <summary type="html">As people who know me understand, I read articles and listen to podcasts on a variety of topics ranging from technology, social science, society, economics, etc. Economics is one of my favourites, as it is very relatable to our day to day lives, besides involving mathematical modelling (which, for the same reasons as Deep Learning techniques of today, can only be close to a very good approximation but never accurate). While listening to BBC’s Business Daily podcasts, I stumbled upon this episode on Modern Monetary Theory. The title of the podcast - “Magic Money Tree” caught my attention and it turned out to be an interesting take on a proposal by one of the former Hedge Fund manager about central banks being able to print more money when needed. I did have this idea when I was a kid before I realized inflation and value of goods and how they are tied to abundance of ciculation of money, interest rates and consumer spending. I am not an economist but I am worried how this could lead to powerful economies manipulating their inflation thereby leading to disastrous consequences in parts of the world whose currencies are not global trade currencies. For those interested in listening to the episode, you can do it here: Are there wonderful teachers among expert economists who can help me understand?</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">The Edge Effect →</title>
      
      <link href="https://dotkay.github.io/2019/01/06/edge-effect/" rel="alternate" type="text/html" title="The Edge Effect" />
      <published>2019-01-06T00:00:00+00:00</published>
      <updated>2019-01-06T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2019/01/06/edge-effect</id>
      <content type="html" xml:base="https://dotkay.github.io/2019/01/06/edge-effect/">&lt;p&gt;On this rainy Sunday in California, with not much motivation to do anything serious, with the last of the India-Australia Test series underway in Sydney delayed due to rain, I started scrolling through the library of my favourite pod-casts and this particular one caught my attention. &lt;em&gt;The Edge Effect&lt;/em&gt; - an episode from NPR’s &lt;a href=&quot;https://www.npr.org/series/423302056/hidden-brain&quot;&gt;Hidden Brain&lt;/a&gt; series.&lt;/p&gt;

&lt;p&gt;The episode talks about the importance of encouraging and developing diversity of thoughts and ideas. It draws examples from science and music and makes compelling arguments supporting diversity. In particular, the experiments by Adam Galinsky and the life story of Cristina Pato were very impressive.&lt;/p&gt;

&lt;p&gt;For those interested, here is a link to the podcast:&lt;/p&gt;

&lt;audio controls=&quot;&quot;&gt;
&lt;source src=&quot;https://play.podtrac.com/npr-510308/npr.mc.tritondigital.com/NPR_510308/media/anon.npr-podcasts/podcast/npr/hiddenbrain/2018/07/20180702_hiddenbrain_hb_diversity_and_creativity__-_final_pod_mix-9012e926-5cd6-4e44-b9d5-0b6e9750801c.mp3&quot; /&gt; 
&lt;/audio&gt;

&lt;p&gt;I should take time to appreciate the diversity my parents exposed me to, while growing up in India.&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="Diversity" />
      
        <category term="Edge Effect" />
      
        <category term="NPR" />
      
        <category term="Hidden Brain" />
      

      

      
        <summary type="html">On this rainy Sunday in California, with not much motivation to do anything serious, with the last of the India-Australia Test series underway in Sydney delayed due to rain, I started scrolling through the library of my favourite pod-casts and this particular one caught my attention. The Edge Effect - an episode from NPR’s Hidden Brain series. The episode talks about the importance of encouraging and developing diversity of thoughts and ideas. It draws examples from science and music and makes compelling arguments supporting diversity. In particular, the experiments by Adam Galinsky and the life story of Cristina Pato were very impressive. For those interested, here is a link to the podcast: I should take time to appreciate the diversity my parents exposed me to, while growing up in India.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Personalized movies … any takers? →</title>
      
      <link href="https://dotkay.github.io/2019/01/02/personalized-movies/" rel="alternate" type="text/html" title="Personalized movies ... any takers?" />
      <published>2019-01-02T00:00:00+00:00</published>
      <updated>2019-01-02T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2019/01/02/personalized-movies</id>
      <content type="html" xml:base="https://dotkay.github.io/2019/01/02/personalized-movies/">&lt;div class=&quot;img_container&quot;&gt;
  &lt;p class=&quot;img=responsive&quot;&gt;&lt;img src=&quot;/assets/images/misc/deewaar2.png&quot; alt=&quot;Amar Akbar Anthony&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;I got into this discussion over lunch when I heard about the Netflix series “Black Mirror” which allows the audience to choose among a set of possible story endings. This is an excellent development, in my view, in that it not only brings more suspense and interest or attention to the content, on the lighter side it would also prevent spoilers.&lt;/p&gt;

&lt;p&gt;Ever since I heard about &lt;a href=&quot;https://newsable.asianetnews.com/kerala/after-solo-other-malayalam-films-supposed-to-have-different-endings&quot;&gt;south Indian movies that had different climaxes&lt;/a&gt; (although to appease the fan base in different regions), I have always wondered why not have multiple possibilities for a movie climax and serve (stream) the appropriate one depending on the goal of the movie audience - i.e., if the goal is to just watch the movie and return home happy, one could have a happy ending, if the viewer is adventurous or an FPS gamer, one could have a violent or tragic ending, etc.&lt;/p&gt;

&lt;p&gt;Now that we have personalization using big data analytics everywhere, it should be possible for a streaming service to identify the likes and dislikes of the audience based on previous perferences, reviews, age, likes, and the many similar features to identify the best climax for each specific viewer, besides providing the viewer the choice to choose from alternate climaxes. Of course, the cost is in the making of several different versions of a movie or TV series which in a way could be reduced using today’s CGI that only gets better over time. The upshot would be more viewership and more discussion centered around the various climaxes. Instead of viewers just watching the movie and rating them, each different climax of the same movie would get rated by different personalities. Such a service could also stream a movie ending in such a way as to cheer you up when you are dull or to pump you up when you are demotivated. Movies will never be the same again!&lt;/p&gt;

&lt;p&gt;If such a personalization of streaming content were to happen who would lead the way? Would it be Amazon Fire TV who has the machine learning backend to make personalization happen, NetFlix who has the influence to get the producers to make several interesting versions of a movie or TV series or Apple TV service if Apple were to get its innovation crown back? What do you think?&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="technology" />
      
        <category term="streaming content" />
      
        <category term="personalization" />
      

      

      
        <summary type="html">I got into this discussion over lunch when I heard about the Netflix series “Black Mirror” which allows the audience to choose among a set of possible story endings. This is an excellent development, in my view, in that it not only brings more suspense and interest or attention to the content, on the lighter side it would also prevent spoilers. Ever since I heard about south Indian movies that had different climaxes (although to appease the fan base in different regions), I have always wondered why not have multiple possibilities for a movie climax and serve (stream) the appropriate one depending on the goal of the movie audience - i.e., if the goal is to just watch the movie and return home happy, one could have a happy ending, if the viewer is adventurous or an FPS gamer, one could have a violent or tragic ending, etc. Now that we have personalization using big data analytics everywhere, it should be possible for a streaming service to identify the likes and dislikes of the audience based on previous perferences, reviews, age, likes, and the many similar features to identify the best climax for each specific viewer, besides providing the viewer the choice to choose from alternate climaxes. Of course, the cost is in the making of several different versions of a movie or TV series which in a way could be reduced using today’s CGI that only gets better over time. The upshot would be more viewership and more discussion centered around the various climaxes. Instead of viewers just watching the movie and rating them, each different climax of the same movie would get rated by different personalities. Such a service could also stream a movie ending in such a way as to cheer you up when you are dull or to pump you up when you are demotivated. Movies will never be the same again! If such a personalization of streaming content were to happen who would lead the way? Would it be Amazon Fire TV who has the machine learning backend to make personalization happen, NetFlix who has the influence to get the producers to make several interesting versions of a movie or TV series or Apple TV service if Apple were to get its innovation crown back? What do you think?</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">New year, Privacy and Security →</title>
      
      <link href="https://dotkay.github.io/2019/01/01/privacy-and-security/" rel="alternate" type="text/html" title="New year, Privacy and Security" />
      <published>2019-01-01T00:00:00+00:00</published>
      <updated>2019-01-01T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2019/01/01/privacy-and-security</id>
      <content type="html" xml:base="https://dotkay.github.io/2019/01/01/privacy-and-security/">&lt;p&gt;Happy New year friends!&lt;/p&gt;

&lt;p&gt;What a year 2018 has been for the topic of privacy and security - from the most loved &lt;a href=&quot;https://www.nytimes.com/2018/03/19/technology/facebook-cambridge-analytica-explained.html&quot;&gt;social network&lt;/a&gt; scrambling for clues to save themselves to the other &lt;a href=&quot;https://www.theguardian.com/technology/2018/dec/10/google-to-shut-down-early-after-privacy-flaw-affects-over-50m-users&quot;&gt;social network&lt;/a&gt; built by the world’s best engineers still couldn’t save their data, besides struggling to stay relevant. While Europe was quick to pass &lt;a href=&quot;https://eugdpr.org/&quot;&gt;GDPR&lt;/a&gt;, many other countries even in the developed world are yet to catch up with such laws and regulations. 2018 was also the year that saw the &lt;a href=&quot;https://techcrunch.com/2018/12/28/smart-speakers-hit-critical-mass-in-2018/&quot;&gt;surge in smart speakers&lt;/a&gt; and home automation - isn’t that ironic?&lt;/p&gt;

&lt;p&gt;But this story is not about the past, but about the future. Many top technology and auto companies rushing to fulfill the promise of self-driving or autonomous vehicles. It will definitely become a reality, to some extent, in at least the parts of the world where the infrastructure supports it. But the notion of foolproof security for such a technology is far from being achieved. With smartphone apps like Facebook, WhatsApp and Google+ security issues, we have only scratched the surface of the malevolent intent that is possible. Once autonomous vehicles and other IoT devices reach critical mass, the security issues are only going to multiply manifold and the impact of security flaws can have disastrous consequences. Imagine a malicious attacker taking control of traffic lights that talk to cars or cars talking to other cars to negotiate who gets to cross an intersection, or a mass rapid transit system that reroutes itself or changes frequency of rides depending on real-time ridership information using neural network based predictions. Imagine the impact of such a thing gone wrong. With the current day deep learning algorithms themselves not being tractable (i.e. one can not reliably track the computation from input data to the prediction step by step as in &lt;a href=&quot;https://skymind.ai/wiki/symbolic-reasoning&quot;&gt;symbolic AI&lt;/a&gt;) it is going to be more challenging to resolve a security issue even after having identified it. Apologies for being pessimistic - but one should see this as a challenge for computer architecture and computer security research - a great time to be working in any of these fields.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you want a job for the next one year, learn web/mobile app development, if you need a job for the next five years, train yourself with deep learning skills, if you need a job for the rest of your life, start working on computer security.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;An interesting short documentary I happened to watch recently:&lt;/p&gt;

&lt;div class=&quot;img_container&quot;&gt;
  &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/KGX-c5BJNFk&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;</content>

      
      
      
      
      

      

      
        <category term="technology" />
      
        <category term="privacy" />
      
        <category term="security" />
      

      

      
        <summary type="html">Happy New year friends! What a year 2018 has been for the topic of privacy and security - from the most loved social network scrambling for clues to save themselves to the other social network built by the world’s best engineers still couldn’t save their data, besides struggling to stay relevant. While Europe was quick to pass GDPR, many other countries even in the developed world are yet to catch up with such laws and regulations. 2018 was also the year that saw the surge in smart speakers and home automation - isn’t that ironic? But this story is not about the past, but about the future. Many top technology and auto companies rushing to fulfill the promise of self-driving or autonomous vehicles. It will definitely become a reality, to some extent, in at least the parts of the world where the infrastructure supports it. But the notion of foolproof security for such a technology is far from being achieved. With smartphone apps like Facebook, WhatsApp and Google+ security issues, we have only scratched the surface of the malevolent intent that is possible. Once autonomous vehicles and other IoT devices reach critical mass, the security issues are only going to multiply manifold and the impact of security flaws can have disastrous consequences. Imagine a malicious attacker taking control of traffic lights that talk to cars or cars talking to other cars to negotiate who gets to cross an intersection, or a mass rapid transit system that reroutes itself or changes frequency of rides depending on real-time ridership information using neural network based predictions. Imagine the impact of such a thing gone wrong. With the current day deep learning algorithms themselves not being tractable (i.e. one can not reliably track the computation from input data to the prediction step by step as in symbolic AI) it is going to be more challenging to resolve a security issue even after having identified it. Apologies for being pessimistic - but one should see this as a challenge for computer architecture and computer security research - a great time to be working in any of these fields. If you want a job for the next one year, learn web/mobile app development, if you need a job for the next five years, train yourself with deep learning skills, if you need a job for the rest of your life, start working on computer security. An interesting short documentary I happened to watch recently:</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Google’s product portfolio →</title>
      
      <link href="https://dotkay.github.io/2018/08/16/google-product-portfolio/" rel="alternate" type="text/html" title="Google's product portfolio" />
      <published>2018-08-16T00:00:00+00:00</published>
      <updated>2018-08-16T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2018/08/16/google-product-portfolio</id>
      <content type="html" xml:base="https://dotkay.github.io/2018/08/16/google-product-portfolio/">&lt;p&gt;Keeping up with my modest goals from the &lt;a href=&quot;https://dotkay.github.io/2018/08/15/deep-learning-and-tech-products&quot;&gt;previous post&lt;/a&gt;, I started looking at Google’s product portfolio.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Why Google? - Why not?&lt;/li&gt;
  &lt;li&gt;Why their product portfolio? - there is such a rich variety catering to different customer segments.&lt;/li&gt;
  &lt;li&gt;Why for this topic (analysing how machine learning and/or deep learning will impact/improve the products)? - Because we already see the impact (like Google translate, maps, etc.)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here’s their product portfolio, right from their webpage:&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;img_container&quot;&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/images/products/G_product_portfolio.png&quot; alt=&quot;Google Product Portfolio&quot; class=&quot;img=responsive&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;In future posts, we will pick products from this list and analyze.&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="technology" />
      
        <category term="products" />
      
        <category term="Google" />
      

      

      
        <summary type="html">Keeping up with my modest goals from the previous post, I started looking at Google’s product portfolio. Why Google? - Why not? Why their product portfolio? - there is such a rich variety catering to different customer segments. Why for this topic (analysing how machine learning and/or deep learning will impact/improve the products)? - Because we already see the impact (like Google translate, maps, etc.) Here’s their product portfolio, right from their webpage: In future posts, we will pick products from this list and analyze.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Deep Learning and Technology Products →</title>
      
      <link href="https://dotkay.github.io/2018/08/15/deep-learning-and-tech-products/" rel="alternate" type="text/html" title="Deep Learning and Technology Products" />
      <published>2018-08-15T00:00:00+00:00</published>
      <updated>2018-08-15T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2018/08/15/deep-learning-and-tech-products</id>
      <content type="html" xml:base="https://dotkay.github.io/2018/08/15/deep-learning-and-tech-products/">&lt;p&gt;I happened to complete an online course on Deep Learning and just starting to look at different products to see how machine learning or deep learning techniques could be used to make these products better. Since I understand technology products and their landscape better, I am likely to be biased in analysing more technology products than non-tech ones, although I am determined to study some non-tech industries, processes, products and services to see if (at all) and how deep learning could be used there - that is a bigger challenge and one that would stimulate our neurons more. Let’s see how I fare …&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="technology" />
      
        <category term="deep learning" />
      
        <category term="Google" />
      

      

      
        <summary type="html">I happened to complete an online course on Deep Learning and just starting to look at different products to see how machine learning or deep learning techniques could be used to make these products better. Since I understand technology products and their landscape better, I am likely to be biased in analysing more technology products than non-tech ones, although I am determined to study some non-tech industries, processes, products and services to see if (at all) and how deep learning could be used there - that is a bigger challenge and one that would stimulate our neurons more. Let’s see how I fare …</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Drones for fire fighting… →</title>
      
      <link href="https://dotkay.github.io/2018/08/11/drones-for-fire-fighting/" rel="alternate" type="text/html" title="Drones for fire fighting..." />
      <published>2018-08-11T00:00:00+00:00</published>
      <updated>2018-08-11T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2018/08/11/drones-for-fire-fighting</id>
      <content type="html" xml:base="https://dotkay.github.io/2018/08/11/drones-for-fire-fighting/">&lt;p&gt;While driving back from a camping along with my friends and looking at the vast possibly burnt areas, we started thinking why even in the &lt;em&gt;so called&lt;/em&gt; hot bed of technology (Silicon Valley) we &lt;a href=&quot;https://www.mercurynews.com/2018/07/30/why-planes-cant-fight-shastas-deadly-carr-fire/&quot;&gt;hear&lt;/a&gt; that fire fighting aircrafts had visibility problems because of the dense smoke. Why can’t we use autonomous drone technology for fighting wild fires (given that we use unmanned drones for warfare). Something to think about seriously.&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="technology" />
      
        <category term="autonomous transport" />
      

      

      
        <summary type="html">While driving back from a camping along with my friends and looking at the vast possibly burnt areas, we started thinking why even in the so called hot bed of technology (Silicon Valley) we hear that fire fighting aircrafts had visibility problems because of the dense smoke. Why can’t we use autonomous drone technology for fighting wild fires (given that we use unmanned drones for warfare). Something to think about seriously.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Languages, mind and our way of thinking… →</title>
      
      <link href="https://dotkay.github.io/2018/07/15/hidden-brain-languages-mind/" rel="alternate" type="text/html" title="Languages, mind and our way of thinking..." />
      <published>2018-07-15T00:00:00+00:00</published>
      <updated>2018-07-15T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2018/07/15/hidden-brain-languages-mind</id>
      <content type="html" xml:base="https://dotkay.github.io/2018/07/15/hidden-brain-languages-mind/">&lt;p&gt;Allez les Bleus!!&lt;/p&gt;

&lt;p&gt;Just happened to listen to this week’s episode of one of the recent NPR podcast series titled &lt;a href=&quot;https://www.npr.org/series/423302056/hidden-brain&quot;&gt;Hidden Brain&lt;/a&gt; and it got me thinking a lot. I speak almost 5 languages (not fluently but to different degrees of expertise) and I am not sure how my mind thinks. One thing for sure though is that I happen to think in my mother tongue and my mind translates it in (almost) real-time while I communicate, be it talking or writing down my thoughts as I do while writing this blog post. If languages do influence our thinking and understanding and more importantly the biases we cultivate, what does it mean for language translators - do they also convey the biases that are inherently influenced by one’s language? Or as a technologist I am also inclined to think what would it mean for AI systems (say chat-bots) that are meant to facilitate communication? I now tend to believe that they have to be designed with the intricacies of languages and the influences, biases that it carries along encoded into the system in order for it to be more acceptable. Even if not as a chat-bot, it would be a great system to train people to work with people of different cultures so that we understand different cultures better and comfortably communicate taking into account their nuances.&lt;/p&gt;

&lt;p&gt;If you are interested in listening to it, here it is:&lt;/p&gt;
&lt;audio controls=&quot;&quot;&gt;
&lt;source src=&quot;https://play.podtrac.com/npr-510308/ondemand.npr.org/anon.npr-mp3/npr/hiddenbrain/2018/07/20180712_hiddenbrain_hb_rad_-_watch_your_mouth__-_final_full_for_web.mp3&quot; /&gt;
&lt;/audio&gt;</content>

      
      
      
      
      

      

      
        <category term="psychology" />
      
        <category term="languages" />
      
        <category term="NPR" />
      

      

      
        <summary type="html">Allez les Bleus!! Just happened to listen to this week’s episode of one of the recent NPR podcast series titled Hidden Brain and it got me thinking a lot. I speak almost 5 languages (not fluently but to different degrees of expertise) and I am not sure how my mind thinks. One thing for sure though is that I happen to think in my mother tongue and my mind translates it in (almost) real-time while I communicate, be it talking or writing down my thoughts as I do while writing this blog post. If languages do influence our thinking and understanding and more importantly the biases we cultivate, what does it mean for language translators - do they also convey the biases that are inherently influenced by one’s language? Or as a technologist I am also inclined to think what would it mean for AI systems (say chat-bots) that are meant to facilitate communication? I now tend to believe that they have to be designed with the intricacies of languages and the influences, biases that it carries along encoded into the system in order for it to be more acceptable. Even if not as a chat-bot, it would be a great system to train people to work with people of different cultures so that we understand different cultures better and comfortably communicate taking into account their nuances. If you are interested in listening to it, here it is:</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Python, dictionaries, mutation and insertion order →</title>
      
      <link href="https://dotkay.github.io/2018/06/30/python-dict-order/" rel="alternate" type="text/html" title="Python, dictionaries, mutation and insertion order" />
      <published>2018-06-30T00:00:00+00:00</published>
      <updated>2018-06-30T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2018/06/30/python-dict-order</id>
      <content type="html" xml:base="https://dotkay.github.io/2018/06/30/python-dict-order/">&lt;p&gt;In an &lt;a href=&quot;https://dotkay.github.io/2018/06/24/python-tuple-mem-mgmt/&quot;&gt;earlier post&lt;/a&gt;, we saw tuples, which are immutable data-types in Python, but in the case of a tuple of lists, we were able to modify the contents of the list. Now, we will see dictionary objects in Python and see if they behave as expected. Recall that dictionaries are mutable objects in Python.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mem_addr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;d1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'memory referenced by d1: {0}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_addr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The memory referenced by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;d1&lt;/code&gt; seems to be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0x28be6286ee8&lt;/code&gt;. Now, let us try to modify the contents of our dictionary. In particular, let us add a new key and a corresponding value.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;d1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'k3'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.5&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'memory referenced by d1: {0}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_addr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The memory referenced by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;d1&lt;/code&gt; still seems to be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0x28be6286ee8&lt;/code&gt;. So, dictionaries seem to be well behaved. I like them.&lt;/p&gt;

&lt;p&gt;However, for people who are still stuck with an older version (Python &amp;lt;= 3.5) and moving to Python &amp;gt;= 3.6, there are some surprises with dictionaries. For example, let us try with Python 3.6 first:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;d2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'d'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'e'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'f'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'g'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'i'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;prints out:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And if you notice, the keys are in order they were specified when &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;d2&lt;/code&gt; was created. With Python &amp;lt;= 3.5 however, this was the output (v2.7.13):&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{'a': 1, 'c': 3, 'b': 2, 'e': 5, 'd': 4, 'g': 7, 'f': 6, 'i': 9, 'h': 8}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The reason for the above surprise is just that in Python 3.6 dictionaries got an order-preserving implementation and it became a standard since Python 3.7.&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="mutable" />
      
        <category term="dict" />
      
        <category term="memory management" />
      
        <category term="insertion order" />
      
        <category term="Python" />
      

      

      
        <summary type="html">In an earlier post, we saw tuples, which are immutable data-types in Python, but in the case of a tuple of lists, we were able to modify the contents of the list. Now, we will see dictionary objects in Python and see if they behave as expected. Recall that dictionaries are mutable objects in Python. def mem_addr(item): return hex(id(item)) d1 = dict(k1 = 1, k2 = 'a') print('memory referenced by d1: {0}'.format(mem_addr(d1))) The memory referenced by d1 seems to be 0x28be6286ee8. Now, let us try to modify the contents of our dictionary. In particular, let us add a new key and a corresponding value. d1['k3'] = 10.5 print('memory referenced by d1: {0}'.format(mem_addr(d1))) The memory referenced by d1 still seems to be 0x28be6286ee8. So, dictionaries seem to be well behaved. I like them. However, for people who are still stuck with an older version (Python &amp;lt;= 3.5) and moving to Python &amp;gt;= 3.6, there are some surprises with dictionaries. For example, let us try with Python 3.6 first: d2 = { 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9 } print(d2) prints out: {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9} And if you notice, the keys are in order they were specified when d2 was created. With Python &amp;lt;= 3.5 however, this was the output (v2.7.13): {'a': 1, 'c': 3, 'b': 2, 'e': 5, 'd': 4, 'g': 7, 'f': 6, 'i': 9, 'h': 8} The reason for the above surprise is just that in Python 3.6 dictionaries got an order-preserving implementation and it became a standard since Python 3.7.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Computing elements that result in maximum product efficiently →</title>
      
      <link href="https://dotkay.github.io/2018/06/29/faster-max-product-items/" rel="alternate" type="text/html" title="Computing elements that result in maximum product efficiently" />
      <published>2018-06-29T00:00:00+00:00</published>
      <updated>2018-06-29T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2018/06/29/faster-max-product-items</id>
      <content type="html" xml:base="https://dotkay.github.io/2018/06/29/faster-max-product-items/">&lt;p&gt;In a &lt;a href=&quot;https://dotkay.github.io/2018/06/25/max-product-items&quot;&gt;previous post&lt;/a&gt; we were wondering if we can compute the elements (from a given unsorted array of integers) that result in maximum product faster than (O(n logn). It turns out we can do a linear scan of the array, keeping track of the largest two and the smallest two elements. One of these pairs would result in the maximum product.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;maxprod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT_MIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT_MAX&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;max2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;max1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;max2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;min2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;min1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;min2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;The algorithm is very straight-forward that the code itself is self explanatory.&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="data structures" />
      
        <category term="arrays" />
      
        <category term="algorithms" />
      
        <category term="C++" />
      

      

      
        <summary type="html">In a previous post we were wondering if we can compute the elements (from a given unsorted array of integers) that result in maximum product faster than (O(n logn). It turns out we can do a linear scan of the array, keeping track of the largest two and the smallest two elements. One of these pairs would result in the maximum product. void maxprod(std::vector&amp;lt;int&amp;gt; arr) { int n = arr.size(); int max1 = arr[0], max2 = INT_MIN; int min1 = arr[0], min2 = INT_MAX; for (int i = 1; i &amp;lt; n; i++) { if (arr[i] &amp;gt; max1) { max2 = max1; max1 = arr[i]; } else if (arr[i] &amp;gt; max2) max2 = arr[i]; if (arr[i] &amp;lt; min1) { min2 = min1; min1 = arr[i]; } else if (arr[i] &amp;lt; min2) min2 = arr[i]; } if (max1 * max2 &amp;gt; min1 * min2) std::cout &amp;lt;&amp;lt; max1 &amp;lt;&amp;lt; &quot;, &quot; &amp;lt;&amp;lt; max2 &amp;lt;&amp;lt; std::endl; else std::cout &amp;lt;&amp;lt; min1 &amp;lt;&amp;lt; &quot;, &quot; &amp;lt;&amp;lt; min2 &amp;lt;&amp;lt; std::endl; } The algorithm is very straight-forward that the code itself is self explanatory.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Computing elements that result in maximum product →</title>
      
      <link href="https://dotkay.github.io/2018/06/25/max-product-items/" rel="alternate" type="text/html" title="Computing elements that result in maximum product" />
      <published>2018-06-25T00:00:00+00:00</published>
      <updated>2018-06-25T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2018/06/25/max-product-items</id>
      <content type="html" xml:base="https://dotkay.github.io/2018/06/25/max-product-items/">&lt;p&gt;Suppose we are given an unsorted array of integers and asked to find the pair of elements from the array that results in maximum product, how do we go about computing it?&lt;/p&gt;

&lt;p&gt;A naïve approach is to find the product of each pair and maintain the maximum product seen so far. This would be an (O(n^2)) algorithm. Let us start with this and improve on it.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;maxprod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_prod&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT_MIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_prod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;max_prod&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;max_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;max_j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;Can we do better than (O(n^2))? Clearly, yes. We know that we could sort an array efficiently in (O(n log n)). We could sort the array and the maximum product would be either the product of the largest two elements or smallest two elements (if they are both negative).&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;maxprod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;Now, can we do better than (O(n log n))?&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="data structures" />
      
        <category term="arrays" />
      
        <category term="algorithms" />
      
        <category term="C++" />
      

      

      
        <summary type="html">Suppose we are given an unsorted array of integers and asked to find the pair of elements from the array that results in maximum product, how do we go about computing it? A naïve approach is to find the product of each pair and maintain the maximum product seen so far. This would be an (O(n^2)) algorithm. Let us start with this and improve on it. void maxprod(std::vector&amp;lt;int&amp;gt; arr) { int n = arr.size(); int max_prod = INT_MIN; int max_i, max_j; for (int i = 0; i &amp;lt; n-1; i++) { for (int j = i + 1; j &amp;lt; n; j++) { if (arr[i] * arr[j] &amp;gt; max_prod) { max_prod = arr[i] * arr[j]; max_i = i; max_j = j; } } } std::cout &amp;lt;&amp;lt; arr[max_i] &amp;lt;&amp;lt; &quot;, &quot; &amp;lt;&amp;lt; arr[max_j] &amp;lt;&amp;lt; std::endl; } Can we do better than (O(n^2))? Clearly, yes. We know that we could sort an array efficiently in (O(n log n)). We could sort the array and the maximum product would be either the product of the largest two elements or smallest two elements (if they are both negative). void maxprod(std::vector&amp;lt;int&amp;gt; arr) { int n = arr.size(); std::sort(arr.begin(), arr.end()); if (arr[0] * arr[1] &amp;gt; arr[n-1] * arr[n-2]) std::cout &amp;lt;&amp;lt; arr[0] &amp;lt;&amp;lt; &quot;, &quot; &amp;lt;&amp;lt; arr[1] &amp;lt;&amp;lt; std::endl; else std::cout &amp;lt;&amp;lt; arr[n-1] &amp;lt;&amp;lt; &quot;, &quot; &amp;lt;&amp;lt; arr[n-2] &amp;lt;&amp;lt; std::endl; } Now, can we do better than (O(n log n))?</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Python, immutable objects and memory management, again →</title>
      
      <link href="https://dotkay.github.io/2018/06/24/python-tuple-mem-mgmt/" rel="alternate" type="text/html" title="Python, immutable objects and memory management, again" />
      <published>2018-06-24T00:00:00+00:00</published>
      <updated>2018-06-24T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2018/06/24/python-tuple-mem-mgmt</id>
      <content type="html" xml:base="https://dotkay.github.io/2018/06/24/python-tuple-mem-mgmt/">&lt;p&gt;In an &lt;a href=&quot;https://dotkay.github.io/2018/06/18/python-tuple-mem-mgmt/&quot;&gt;earlier post&lt;/a&gt;, we saw how immutable objects like tuples are handled by Python’s memory management. It was straight-forward - tuples are immutable and so, when we try to update the tuple object, Python creates a new reference. Or does it? Always?&lt;/p&gt;

&lt;p&gt;Let us consider the following tuple, this time a &lt;em&gt;tuple of lists&lt;/em&gt;. Recall that lists in Python are mutable objects.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mem_addr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'memory referenced by t: {0}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_addr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And our output:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;([1, 2], [4, 5])
memory referenced by t: 0x2103c874a48
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We see that the memory referenced by the object &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt; which in our case is a tuple is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0x2103c874a48&lt;/code&gt;. And we know that tuples are immutable objects in Python. So, let’s try to change the above tuple object &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt;. This time we are going to do that by updating the individual elements &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;b&lt;/code&gt; that constitute our tuple object.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'memory referenced by t: {0}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_addr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And we get the following printed:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;([1, 2, 3], [4, 5, 6])
memory referenced by t: 0x2103c874a48
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;img_container&quot;&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/images/py/tup_mem_mgmt_2.png&quot; alt=&quot;Python Memory Management&quot; class=&quot;img=responsive&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;And what just happened here? Our immutable object &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt; got updated without a new reference being created. So, it is not just the object itself that matters, the type of the constituent objects also plays a role in memory management. Hope this is enough motivation to play around with different mutable and immutable objects and how Python’s memory management handles them.&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="immutable" />
      
        <category term="tuples" />
      
        <category term="memory management" />
      
        <category term="Python" />
      

      

      
        <summary type="html">In an earlier post, we saw how immutable objects like tuples are handled by Python’s memory management. It was straight-forward - tuples are immutable and so, when we try to update the tuple object, Python creates a new reference. Or does it? Always? Let us consider the following tuple, this time a tuple of lists. Recall that lists in Python are mutable objects. def mem_addr(item): return hex(id(item)) a = [1, 2] b = [4, 5] t = (a, b) print(t) print('memory referenced by t: {0}'.format(mem_addr(t))) And our output: ([1, 2], [4, 5]) memory referenced by t: 0x2103c874a48 We see that the memory referenced by the object t which in our case is a tuple is 0x2103c874a48. And we know that tuples are immutable objects in Python. So, let’s try to change the above tuple object t. This time we are going to do that by updating the individual elements a and b that constitute our tuple object. a.append(3) b.append(6) print(t) print('memory referenced by t: {0}'.format(mem_addr(t))) And we get the following printed: ([1, 2, 3], [4, 5, 6]) memory referenced by t: 0x2103c874a48 And what just happened here? Our immutable object t got updated without a new reference being created. So, it is not just the object itself that matters, the type of the constituent objects also plays a role in memory management. Hope this is enough motivation to play around with different mutable and immutable objects and how Python’s memory management handles them.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Computing maximum length subarray that sums to 0 →</title>
      
      <link href="https://dotkay.github.io/2018/06/20/max-len-zero-sum-subarr/" rel="alternate" type="text/html" title="Computing maximum length subarray that sums to 0" />
      <published>2018-06-20T00:00:00+00:00</published>
      <updated>2018-06-20T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2018/06/20/max-len-zero-sum-subarr</id>
      <content type="html" xml:base="https://dotkay.github.io/2018/06/20/max-len-zero-sum-subarr/">&lt;p&gt;In a &lt;a href=&quot;https://dotkay.github.io/2018/06/15/all-zero-sum-subarrays&quot;&gt;previous post&lt;/a&gt; we saw how to compute all the subarrays (formed by consecutive elements of an array) that sum to zero. Here, we are going to compute the maximum length one among all those subarrays. You might think why it needs a separate post - one can store all the computed subarrays in a vector and find the maximum of the sizes of the vectors. But one could in fact keep track of the maximum length as and when we compute the individual subarrays that sum to zero.&lt;/p&gt;

&lt;p&gt;Let us look at the naïve approach, as it would be much simpler to understand, and incorporate this computation into it.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max_len_subarr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;max len: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;

&lt;p&gt;We initialized a variable &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_len&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt; and update it as and when we find the starting and ending indices of the subarray that sums to zero. We can extend the same idea to the linear scan algorithm, as below:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;
  &lt;pre&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max_len_subarr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unordered_multimap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;max len: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;</content>

      
      
      
      
      

      

      
        <category term="data structures" />
      
        <category term="arrays" />
      
        <category term="algorithms" />
      
        <category term="C++" />
      

      

      
        <summary type="html">In a previous post we saw how to compute all the subarrays (formed by consecutive elements of an array) that sum to zero. Here, we are going to compute the maximum length one among all those subarrays. You might think why it needs a separate post - one can store all the computed subarrays in a vector and find the maximum of the sizes of the vectors. But one could in fact keep track of the maximum length as and when we compute the individual subarrays that sum to zero. Let us look at the naïve approach, as it would be much simpler to understand, and incorporate this computation into it. void max_len_subarr(std::vector&amp;lt;int&amp;gt; arr) { int n = arr.size(); int max_len = 0; for (int i = 0; i &amp;lt; n; i++) { int acc = 0; for (int j = i; j &amp;lt; n; j++) { acc += arr[j]; if (acc == 0) { int len = j - i + 1; max_len = std::max(len, max_len); } } } std::cout &amp;lt;&amp;lt; &quot;max len: &quot; &amp;lt;&amp;lt; max_len; } We initialized a variable max_len to 0 and update it as and when we find the starting and ending indices of the subarray that sums to zero. We can extend the same idea to the linear scan algorithm, as below: void max_len_subarr(std::vector&amp;lt;int&amp;gt; arr) { int n = arr.size(); std::unordered_multimap&amp;lt;int, int&amp;gt; lookup; lookup.insert(std::pair&amp;lt;int, int&amp;gt;(0, -1)); int max_len = 0; int acc = 0; for (int i = 0; i &amp;lt; n; i++) { acc += arr[i]; if (lookup.find(acc) != lookup.end()) { auto it = lookup.find(acc); while (it != lookup.end() &amp;amp;&amp;amp; it-&amp;gt;first == acc) { int len = i - (it-&amp;gt;second + 1); max_len = std::max(len + 1, max_len); it++; } } lookup.insert(std::pair&amp;lt;int, int&amp;gt;(acc, i)); } std::cout &amp;lt;&amp;lt; &quot;max len: &quot; &amp;lt;&amp;lt; max_len &amp;lt;&amp;lt; std::endl; }</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Python, immutable data-types again, and memory management →</title>
      
      <link href="https://dotkay.github.io/2018/06/18/python-tuple-mem-mgmt/" rel="alternate" type="text/html" title="Python, immutable data-types again, and memory management" />
      <published>2018-06-18T00:00:00+00:00</published>
      <updated>2018-06-18T00:00:00+00:00</updated>
      <id>https://dotkay.github.io/2018/06/18/python-tuple-mem-mgmt</id>
      <content type="html" xml:base="https://dotkay.github.io/2018/06/18/python-tuple-mem-mgmt/">&lt;p&gt;In an &lt;a href=&quot;https://dotkay.github.io/2018/06/01/python-var-mem-mgmt/&quot;&gt;earlier post&lt;/a&gt; we saw how Python’s memory management behaves when dealing with immutable objects. In this post, let us see another immutable object, this time a &lt;em&gt;tuple&lt;/em&gt; and examine how Python deals with it.&lt;/p&gt;

&lt;p&gt;Let us consider a tuple of integer objects &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t = (1, 2, 3)&lt;/code&gt;. We see that it references memory address &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0x1dd65ac45e8&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mem_addr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'memory referenced by t: {0}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_addr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What happens if we try to mutate or update the tuple object above, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&lt;/code&gt;? We see that it creates a new reference to a new object (at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0x1dd65a514c8&lt;/code&gt;), instead of updating the earlier object. And the earlier reference would be reclaimed by the garbage collector.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;img_container&quot;&gt;
  &lt;p&gt;&lt;img src=&quot;/assets/images/py/tup_mem_mgmt_1.png&quot; alt=&quot;Python Memory Management&quot; class=&quot;img=responsive&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'memory referenced by t: {0}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_addr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is because &lt;em&gt;tuples&lt;/em&gt; are immutable objects, more like integer objects we saw in an &lt;a href=&quot;https://dotkay.github.io/2018/06/01/python-var-mem-mgmt/&quot;&gt;earlier post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So, all is clear and good, right? Wait until a future post on tuples again.&lt;/p&gt;</content>

      
      
      
      
      

      

      
        <category term="immutable" />
      
        <category term="tuples" />
      
        <category term="memory management" />
      
        <category term="Python" />
      

      

      
        <summary type="html">In an earlier post we saw how Python’s memory management behaves when dealing with immutable objects. In this post, let us see another immutable object, this time a tuple and examine how Python deals with it. Let us consider a tuple of integer objects t = (1, 2, 3). We see that it references memory address 0x1dd65ac45e8 def mem_addr(item): return hex(id(item)) t = (1, 2) print('memory referenced by t: {0}'.format(mem_addr(t))) What happens if we try to mutate or update the tuple object above, t? We see that it creates a new reference to a new object (at 0x1dd65a514c8), instead of updating the earlier object. And the earlier reference would be reclaimed by the garbage collector. t = (1, 2, 3) print('memory referenced by t: {0}'.format(mem_addr(t))) This is because tuples are immutable objects, more like integer objects we saw in an earlier post. So, all is clear and good, right? Wait until a future post on tuples again.</summary>
      

      
      
    </entry>
  
  
</feed>
