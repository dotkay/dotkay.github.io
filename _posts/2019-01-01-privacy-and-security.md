---
layout: post
title: New year, Privacy and Security
categories: [technology, privacy, security]
keywords: [technology, privacy, security]
external-url: https://dotkay.github.io/2019/01/01/privacy-and-security
mathjax: true
---

Happy New year friends!

What a year 2018 has been for the topic of privacy and security - from the most loved [social network](https://www.nytimes.com/2018/03/19/technology/facebook-cambridge-analytica-explained.html) scrambling for clues to save themselves to the other [social network](https://www.theguardian.com/technology/2018/dec/10/google-to-shut-down-early-after-privacy-flaw-affects-over-50m-users) built by the world's best engineers still couldn't save their data, besides struggling to stay relevant. While Europe was quick to pass [GDPR](https://eugdpr.org/), many other countries even in the developed world are yet to catch up with such laws and regulations. 2018 was also the year that saw the [surge in smart speakers](https://techcrunch.com/2018/12/28/smart-speakers-hit-critical-mass-in-2018/) and home automation - isn't that ironic?

But this story is not about the past, but about the future. Many top technology and auto companies rushing to fulfill the promise of self-driving or autonomous vehicles. It will definitely become a reality, to some extent, in at least the parts of the world where the infrastructure supports it. But the notion of foolproof security for such a technology is far from being achieved. With smartphone apps like Facebook, WhatsApp and Google+ security issues, we have only scratched the surface of the malevolent intent that is possible. Once autonomous vehicles and other IoT devices reach critical mass, the security issues are only going to multiply manifold and the impact of security flaws can have disastrous consequences. Imagine a malicious attacker taking control of traffic lights that talk to cars or cars talking to other cars to negotiate who gets to cross an intersection, or a mass rapid transit system that reroutes itself or changes frequency of rides depending on real-time ridership information using neural network based predictions. Imagine the impact of such a thing gone wrong. With the current day deep learning algorithms themselves not being tractable (i.e. one can not reliably track the computation from input data to the prediction step by step as in [symbolic AI](https://skymind.ai/wiki/symbolic-reasoning)) it is going to be more challenging to resolve a security issue even after having identified it. Apologies for being pessimistic - but one should see this as a challenge for computer architecture and computer security research - a great time to be working in any of these fields.

> If you want a job for the next one year, learn web/mobile app development, if you need a job for the next five years, train yourself with deep learning skills, if you need a job for the rest of your life, start working on computer security.

An interesting short documentary I happened to watch recently:

<iframe width="560" height="315" align="center" src="https://www.youtube.com/embed/KGX-c5BJNFk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
