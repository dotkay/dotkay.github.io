<!DOCTYPE html>
<html lang="en">
  <head>
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']],
            processEscapes: true
          }
        });
    </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML">
  </script>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  
  
  <title>Kalyan</title>
  <meta name="description" content="Learning by teaching">
  

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="https://dotkay.github.io/posts/2/">
  
  
  <link rel="alternate" type="application/rss+xml" title="Kalyan" href="https://dotkay.github.io/feed.xml">

  

  
  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:title" content="Kalyan">
  <meta name="twitter:description" content="Learning by teaching">
  
  

  <script type="text/javascript">
  WebFontConfig = {
    google: { families: [ 'Bitter:400,700,400italic:latin' ] }
  };
  (function() {
    var wf = document.createElement('script');
    wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
      '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
    wf.type = 'text/javascript';
    wf.async = 'true';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(wf, s);
  })();
</script>

  
  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-105390377-1', 'auto');
    ga('send', 'pageview');

  </script>


</head>


  <body>

    <header class="site-header">

  <div class="wrapper">
    <a class="site-title" href="/">Kalyan</a> 
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/">About</a>
      
        
        <a class="page-link" href="/archives/">Posts</a>
      
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home">

  

  

  <ul class="post-list">
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            <a class="post-link" href="/2022/08/17/ai-innovation-layers/">The Different Layers of AI Innovation &rarr;</a>
          </h1>

          <p class="post-meta">Aug 17, 2022 • 
  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/ai-ml/">AI/ML</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/dl-accelerators/">DL Accelerators</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/frameworks/">Frameworks</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/algorithms/">Algorithms</a>
    
  
    
  
    
  
    
  
    
  
    
  
    
  

</p>
        </header>

        <div class="post-content">
          <p>When we hear about AI applications these days, either companies like NVIDIA or Graphcore is in focus or the companies that develop applications like OpenAI or Meta is in focus. However there are several layers to AI. Understanding what constitutes the different layers and which companies are the key players in any or many of the layers would enable one to identify moats, challenges and growth drivers of such companies. Besides, one could also identify potential for future opportunities for vertical integration and consolidation.</p>

<p>AI had many winters over the last several decades. However, over the last decade AI enabled applications seem to be proliferating and has already been infused with several day to day software applications - like voice assistants, maps, translators, etc. Two key developments that happened over the last couple of decades are chiefly responsible for this proliferation:</p>

<ol>
  <li>Availability of data, due to inexpensive sensors (image sensors like camera, messages in social media apps, etc.)</li>
  <li>Availability of compute, due to faster CPUs and GPUs</li>
</ol>

<p>Looking at just the two key components would mislead us to think about just software to process the data and hardware to execute the software. One might want to break it down into further components in order to identify the key players in each of the components.</p>

<p><strong>Layers of AI</strong></p>

<p><br /></p>
<div class="img_container">
  <center><img src="https://raw.githubusercontent.com/dotkay/dotkay.github.io/source/assets/images/misc/ai_layers.png" /></center>
</div>

<p><strong>Hardware Accelerator Layer</strong></p>

<p>This is the one of the main layers that brought AI research out of its many winters. <a href="https://inria.hal.science/inria-00112631/document">Kumar’s work</a> at Microsoft Research, <a href="https://people.idsia.ch/~juergen/ijcai2011.pdf">Dan Ciresan’s work</a> at IDSIA on accelerating CNNs (Convolutional Neural Networks) using GPUs followed by the famous <a href="https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">AlexNet work</a> brought attention to the use of hardware acclerators like GPUs for applications that are heavy on matrix computations. GPUs are Single Instruction Multiple Data (SIMD) architecture machines that could excel at tasks that are massively parallel. Subsequently, there were other accelerators built based on other architectures like Bulk Synchronous Processing (BSP) (e.g. Graphcore), or Systolic Arrays (e.g. TPUs) that were targeted on accelerating specific architectures. A broad install base as well as accelerators fine tuned over a long period of time to excel at specific deep learning model architectures and deep learning frameworks could serve as a moat that prevents others from having a slice of the market share easily. A good analogy is to think of hardware layer as the muscles that enable heavy computations.</p>

<p><strong>System Software/Compiler Layer</strong></p>

<p>The System Software or Compiler Layer sits closest to the hardware accelerator thereby optimizing the executions of machine instructions as much as possible. CUDA and OpenCL are the programming models closely tied to the software drivers (system software) or compilers. Lately, Graphcore has graph compilers that optimizes the execution of graph networks (using the Poplar SDK) on Graphcore IPUs. There are also companies like Groq that make a much tighter integration between the compiler layer and the hardware layer. In particular, the Groq compiler does all the optimizations on the input model and continuously orchestrates the instructions as operands for those instructions arrive, with the exact knowledge of which hardware execution units are available to execute the instructions.</p>

<p><strong>Model Architecture Layer</strong></p>

<p>It is not often that one can separate out this layer. Once certain model architectures become stabilized, it might make sense to optimize the layers beneath it (hardware and system software layers) in order to serve this particular architecture. The popular architectures might be Transformers for languages, Convolutional Neural Networks for Images, Graph Neural Networks for graph datasets, etc. However, since newer algorithms are still being developed, the current trends are more about optimizing the hardware and system software layers to optimize specific components of the models. The <a href="https://blogs.nvidia.com/blog/2022/03/22/h100-transformer-engine/">Transformer Engine</a> in H100 GPUs would be an example of such an optimization.</p>

<p><strong>Deep Learning (DL) Frameworks Layer</strong></p>

<p>The different DL Frameworks like Tensorflow, PyTorch, JAX, etc. are similar superficially and have over the years become more similar than different. However, there are compiler instrumentations that optimize such frameworks, very much like Groq Compiler, NVIDIA CUDA, OpenAI Triton, etc. Some of the optimizations like operator fusion have been adopted by the DL frameworks like PyTorch by default and many more such optimizations might become default as research and engineering in DL advances. This layer is also important as it might turn out to be critical to the iterative development of algorithms. Most DL algorithms are iterative in nature and having fine grained control over the progress of the experiments in terms of debugging, performance analysis and the like would ultimately determine the popularity, adoption and subsequently advances in such frameworks. For example, PyTorch executes eagerly using dynamic graphs, it was much easier for programmers to monitor. Tensorflow moved to eager execution from later versions. Which framework is best suited is an ongoing debate in the community with academic researchers leaning towards PyTorch and production engineers leaning towards Tensorflow. There have been other frameworks which were popular initially but lost steam over time.</p>

<p><strong>Algorithms Layer</strong></p>

<p>Algorithmic innovations have led to developments in newer, efficient and more effective model architectures. Though some of the algorithms have been known for a very long time (like backpropagation, CNNs, etc.) the development in other layers (availability of general purpose programmable hardware accelerators, easy-to-use DL frameworks and most importantly the availability of data to train the networks) have significantly aided advancements in algorithms. 
This has led to architectures like <em>Transformers</em> with layers like <em>Attention</em> that seem to push forward the state-of-the-art in DL research. However, it wasn’t an easy innovation and it is definitely not the last - researchers tried different architectures from Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM), Sequence-to-Sequence models, etc. before iteratively discovering the bottlenecks and devising newer architectures to optimize those. If one of these algorithms were determined to be the most optimal, it would make sense to bake it in silicon in order to get the most efficient performance. It has not happened yet as one does not know what future architectures would bring in this fast paced world of DL research.</p>

<p><strong>Data Layer</strong></p>

<blockquote>
  <p>There were 5 exabytes of information created between the dawn of civilization through 2003, but that much information is now created every 2 days.”  – <em>Eric Schmidt</em></p>
</blockquote>

<p><em>Data</em> along with <em>Compute</em> is one of the key drivers of today’s Deep Learning advances. The growth and availability of inexpensive sensors and access to analyze them has put all the algorithms that were developed in theory over the past several decades into practice within a span of a decade. However, as DL applications impermeate more and more of our lives, there would be questions around the source of <em>data</em> the models were trained on and if the data provider was compensated for the same. Further, the emergent behaviors of today’s AI systems are the result of the data they were trained on but without having the ability to trace back the emergent behavior to the data points that led to it. These would be the areas of research that could eventually lead to <em>explainable AI</em> systems that we aspire for.</p>

<p><strong>Reasoning Layer</strong></p>

<p>Different from logical reasoning systems which were referred to as <em>reasoning engines</em>, today’s AI systems are more <em>analogy engines</em> than reasoning ones. The exceptional efficiency and effectiveness of such systems seem to be the result of emergent behavior arising from training these systems on unbelievably vast quantities of data. Even with its effectiveness in language tasks, such AI systems seem to be not so good at logical reasoning. The infusion of logical reasoning behaviors into analogy based reasoning architectures of today’s systems would possibly create effective systems that is also able to reason about its emergent behaviors. Since the research in this area is not very well developed at the time of this writing, it is depicted as a grey box in the image above.</p>

<p><strong>Regulatory Layer</strong></p>

<p>This layer is still an underdeveloped layer (and hence depicted using dotted lines). With recent discussions around the data the systems are trained on and the transparency of algorithms and their explainability, this layer might encompass more than just the data layer and the algorithms layer. In the coming years the systems are likely to get regulated in order to deter inappropriate usage of such systems.</p>

<p>It is indeed a great time for AI - the recent advances in research, several applications and multitude of challenges will make the next few years something exciting to look forward to.</p>

        </div>
        
      </li>
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            <a class="post-link" href="/2022/04/24/logic-languages-reasoning/">Logic, Languages and Reasoning &rarr;</a>
          </h1>

          <p class="post-meta">Apr 24, 2022 • 
  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/nlp/">NLP</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/logic/">logic</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/reasoning/">reasoning</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/computation/">computation</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/nltk/">NLTK</a>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

</p>
        </header>

        <div class="post-content">
          <p>Human languages developed and evolved over thousands of years. Though most languages have a structure (defined by the rules of grammar) we think of spoken languages as a series of informal statements (“informal” compared to the “formal” rigor of mathematical statements). While informal statements helped human species to communicate and collaborate, eventually evolving languages themselves, informal statements were not enough for settling arguments, legal disputes or discovering (new) knowledge from existing knowledge. Socrates, Plato’s teacher, is credited with coming up with inductive arguments and universal definitions. Aristotle’s logic consisted of formulating statements and deriving new knowledge (conclusion) from the knowledge contained in a set of statements (<em>premises</em>) guided by rules that he called <em>syllogisms</em>. Aristotle, a student of Plato, is credited with the earliest study of logic, <em>formal logic</em>, in his collected works <a href="https://archive.org/details/AristotleOrganon/mode/2up"><em>Organon</em></a>. Plato also contributed to the study of reasoning. While Plato relied on <em>deduction</em> from <em>a priori</em> knowledge and postulated that knowledge of things that happen can be deduced from the knowledge of universal ideas, Aristotle’s epistemology postulated that knowledge of things that happen build up to universal knowledge collectively. Together the main recipes for reasoning - induction, deduction and abduction - were discovered that are the pillars for making reasoning infallible.</p>

<p>Mathematicians developed it further for mathematical reasoning which got shaped, like many mathematical computations, into <em>automated reasoning</em> using computer programs by computer scientists. Mathematical logic is the cornerstone of systems that are used for reasoning about the correctness of computer programs.</p>

<p>We can use <a href="https://www.nltk.org/">NLTK</a>’s Python API to play with it to see what it means to encode English sentences as logical formulas. Once we are able to encode knowledge (in English sentences) we can use well formed rules of logic to deduce new information, also called <em>logical inference</em>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">load_parser</span>
<span class="n">grammar_file</span> <span class="o">=</span> <span class="s">'file:///nltk_data/grammars/book_grammars/simple-sem.fcfg'</span>
<span class="n">lp</span> <span class="o">=</span> <span class="n">load_parser</span><span class="p">(</span><span class="n">grammar_file</span><span class="p">)</span>
<span class="n">stmt</span> <span class="o">=</span> <span class="s">'Angus gives a bone to every dog'</span>
<span class="n">trees</span> <span class="o">=</span> <span class="n">lp</span><span class="p">.</span><span class="n">parse</span><span class="p">(</span><span class="n">stmt</span><span class="p">.</span><span class="n">split</span><span class="p">())</span>
<span class="k">for</span> <span class="n">tree</span> <span class="ow">in</span> <span class="n">trees</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">tree</span><span class="p">.</span><span class="n">label</span><span class="p">()[</span><span class="s">'SEM'</span><span class="p">])</span>
</code></pre></div></div>

<p>This gives the semantics in the form of a logical formula:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>all z2.(dog(z2) -&gt; exists z1.(bone(z1) &amp; give(angus,z1,z2)))
</code></pre></div></div>

<p>Further more, one could use the theorem prover that comes along with NLTK to check for consistency among statements and prove goals (conclusion) given a list of statements (premises). For example, one could write</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mini_has_ball</span> <span class="o">=</span> <span class="n">read_expr</span><span class="p">(</span><span class="s">'has(mini)'</span><span class="p">)</span>
<span class="n">mini2jane</span> <span class="o">=</span> <span class="n">read_expr</span><span class="p">(</span><span class="s">'pass(mini, jane)'</span><span class="p">)</span>
<span class="n">rules</span> <span class="o">=</span> <span class="n">read_expr</span><span class="p">(</span><span class="s">'all x. all y. (pass(x, y) -&gt; has(y))'</span><span class="p">)</span>
</code></pre></div></div>

<p>We just encoded some English statements as well as the assumption that if <em>x</em> passes the ball to <em>y</em>, then <em>y</em> will have the ball. We can use a theorem prover to prove a goal that <em>jane has the ball</em> and check if it follows from our assumptions, i.e. of the goal can be derived given the assumptions</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">jane_has_ball</span> <span class="o">=</span> <span class="n">read_expr</span><span class="p">(</span><span class="s">'has(jane)'</span><span class="p">)</span>
<span class="n">prover</span> <span class="o">=</span> <span class="n">nltk</span><span class="p">.</span><span class="n">Prover9</span><span class="p">()</span>
<span class="n">prover</span><span class="p">.</span><span class="n">prove</span><span class="p">(</span><span class="n">jane_has_ball</span><span class="p">,</span> <span class="p">[</span><span class="n">rules</span><span class="p">,</span> <span class="n">mini2jane</span><span class="p">])</span>
</code></pre></div></div>
<p>and the prover, if it can establish a proof, will return:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>True
</code></pre></div></div>

<p>This kind of encoding and logical reasoning might be needed to answer questions like the last one we saw in a <a href="https://dotkay.github.io/2022/03/21/languages-logic-computation">previous post</a>. One might also need more expressive logics in order to encode statements about temporal events succinctly. However, languages themselves are stochastic systems which would imply that we would never be able to come up with logically accurate formulations of the sentences we use in everyday conversations, especially when it involves conversations involving languages that are not one’s native language and might have grammatical mistakes and still convey the intended message. Legal documents or financial documents, for example, could be structured in a precise format that might allow one to formulate the sentences in a logical language and make queries that can return an accurate answer that can be reasoned about if needed - think of a healthcare database to which policy makers submit queries in a natural language. A deep learning based approach, which looks at several usage patterns, to arrive at an approximate formulation which would still enable one to deduce new information from a set of facts already provided. This would be more crucial in developing (explainable) AI systems that can be reasoned about, which is especially crucial in healthcare and other critical domains where AI systems are beginning to find their place.</p>

<p><img src="https://images.metmuseum.org/CRDImages/ep/original/DP-13139-001.jpg#center" alt="img" />
<em>Death of Socrates, by Jacques Louis David (Credits: The Met)</em></p>


        </div>
        
      </li>
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            <a class="post-link" href="/2022/03/21/languages-logic-computation/">Languages, Logic and Computation &rarr;</a>
          </h1>

          <p class="post-meta">Mar 21, 2022 • 
  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/nlp/">NLP</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/logic/">logic</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/computation/">computation</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/openai/">OpenAI</a>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

</p>
        </header>

        <div class="post-content">
          <p>A <a href="https://dotkay.github.io/2022/02/22/languages-culture-communication">previous post</a> spoke about state-of-the-art NLP systems that are based on Transformers and some of the challenges around using such systems for translations. Although they could translate almost accurately, they may not match the nuances of spoken (informal) languages. There are other challenges around <em>Question Answering</em> systems - another tasks such NLP systems are capable of doing. In this post, this is explored futher to see when some computation (as in logical inference rather than mathematical inference) is needed to come up with an answer. We play with <a href="https://openai.com/">OpenAI</a> APIs to see how the state-of-the-art NLP systems excel at language understanding and also where they have gaps to fill.</p>

<p>English, like many other languages, is a little ambiguous. There are well established rules of English grammar but I believe there are several statements in common parlance that have introduce some ambiguity. While I tried <a href="https://openai.com/">OpenAI</a>, in particular the <code class="language-plaintext highlighter-rouge">text-davinci-002</code> engine on a variety of English statements and the results were astounding, when I kept going on, there were some statements where the answer was not exactly clear.</p>

<p>One of the was what <em>she</em> refers to in a statement like <em>Anna hit Clara because she was drunk</em>. Though it looks ambiguous I believe as <em>Anna</em> is the subject, the <em>she</em> in the statement must refer to <em>Anna</em>. OpenAI does seem to tell me that the <em>she</em> in the statement refers to <em>Anna</em>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; response = openai.Completion.create(
      engine="text-davinci-002",
      prompt="Anna hit Clara because she was drunk.\n\nQ: Who was drunk?\nA:",
      top_p=1,
      ...
    )
&gt;&gt;&gt; print(response)
{
  "choices": [
    {
      ...
      "text": " Anna was drunk."
    }
  ],
...
}
</code></pre></div></div>

<p>If I rephrase the above statement as <em>Anna hit Clara because she was drunk. Was Clara drunk?</em>, OpenAI was humble enough to admit that it does not know, which is impressive as there isn’t enough context to infer if <em>Clara</em> was drunk.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; response = openai.Completion.create(
      engine="text-davinci-002",
      prompt="Anna hit Clara because she was drunk.\n\nQ: Was Clara drunk?\nA:",
      ...
      stop=["\n"]
    )
&gt;&gt;&gt; print(response)
{
  "choices": [
    {
      ...
      "text": " I don't know."
    }
  ],
  ...
}
</code></pre></div></div>

<p>What impressed me the most was the ability to do formulaic calculations and return an answer.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; response = openai.Completion.create(
      engine="text-davinci-002",
      prompt="The sale price of a decent house in California is about a million dollars. 20%
      of the price needs to be paid as down payment. In addition, the county levies a 
      property tax of 1.2% on the sale price of the house. John takes a 30 year fixed rate 
      mortgage at 3.5% interest rate.\n\nQ: What would be John's monthly cost of ownership? 
      \nA:",
      ...
    )
&gt;&gt;&gt; print(response)
{
  "choices": [
    {
      ... 
      "text": " John's monthly cost of ownership would be $4,167."
    }
  ],
  ...
}
</code></pre></div></div>

<p>While the ability to solve when numerical information was provided was too impressive, there was some struggle when the answer involved logical interpretation and numerical computation. For example, the query in the following requires interpreting what “boundary” is and how it contributes to the answer.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; response = openai.Completion.create(
      engine="text-davinci-002",
      prompt="Dhoni scored a single off the first ball of the 11th over. Sachin scored two
      consecutive boundaries followed by a single. Dhoni hit the biggest six of the match. 
      He then followed it up with a single and retained strike. \n\nQ: How many runs were 
      scored off the 11th over? \nA:",
      ...
    )
&gt;&gt;&gt; print(response)
{
  "choices": [
    {
      ...
      "text": " 15"
    }
  ],
  ...
}
</code></pre></div></div>

<p>Human languages are such that they involve logical interpretation, deduction and computation. It is precisely this challenge that leads to misinterpretation, miscommunication and chaos - you can think of the last time a celebrity or a politican claimed his comments were misinterpreted or taken out of context. However, we as human beings deal with these every day and are attuned to the fallacies and inaccuracies. Our communication system, the one that distinguishes us from many other species, is itself a stochastic one.</p>

<p>Some statements require logical deduction which is challenging for deep learning systems (that learn from patterns contained in a training corpus). For example,</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; response = openai.Completion.create(
      engine="text-davinci-002",
      prompt="marco passed the ball to miel, miel quickly gave it to don who passed it on to
      sky. sky ran with it for a while and gave it to anna.\n\nQ: Does marco have the ball 
      now?\nA:",
      ...
   )
   &gt;&gt;&gt; print(response)
{
  "choices": [
    {
      ...
      "text": " No"
    }
  ],
  ...
}
</code></pre></div></div>

<p>While the system is able to deduce that <em>marco</em> does not have the ball, a deduction performed to answer <em>who has the ball?</em> doesn’t seem to work well.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; response = openai.Completion.create(
      engine="text-davinci-002",
      prompt="marco passed the ball to miel, miel quickly gave it to don who passed it on to
      sky. sky ran with it for a while and gave it to anna.\n\nQ: Who has the ball now?\nA:",
      ...
    )
&gt;&gt;&gt; print(response)
{
  "choices": [
    {
      ...
      "text": ""
    }
  ],
  ...
}
</code></pre></div></div>

<p>There is immense research interest in this area and the progress being made is as impressive as that has been achieved so far. Hopefully, in a future post, I will be able to show an NLP system that combines logical reasoning with deep learning and is able to answer much more fancier questions. I am looking forward to it.</p>

        </div>
        
      </li>
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            <a class="post-link" href="/2022/02/22/languages-culture-communication/">Languages, Culture and Communication &rarr;</a>
          </h1>

          <p class="post-meta">Feb 22, 2022 • 
  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/nlp/">NLP</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/languages/">Languages</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/hugging-face/">Hugging Face</a>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

</p>
        </header>

        <div class="post-content">
          <p>Languages have always played a very important role in society and in our cultural evolutions. It has been the vehicle that allowed human beings to collaborate, coexist and achieve great things as well as to deceive, conspire and destroy. Languages have also evolved over time carrying with them many cultural norms, shades of history while also losing some. The same language might sound differently across an ocean or even across geographic land boundaries. Some languages like Sanskrit, though less ambiguous and more efficient, are struggling to survive while others like English are flourishing despite being more ambiguous. In the age of AI based natural language processing (NLP) is it possible to encode some of these norms and cultural connotations in order to make automated translations more close to native spoken languages?</p>

<p>NLP systems are a commonplace today, mostly in the form of personal assistants like Alexa and chatbots like a customer service system. While they are able to understand and respond to usual queries or translate text to a surprising level of accuracy, they are far from matching human levels of communication. My claim is that NLP research is yet to discover the means to encode the several cultural connotations that come with languages, especially while translating from one to another. While NLP algorithms like LSTM and <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">Transformers</a> implicitly encode some of the context needed for better understanding of a statement, a pair of languages might be too different to capture all the context implicitly. Is capturing all of the context necessary? May not be. However, capturing important nuances might be.</p>

<p>I have been playing around with the <a href="https://huggingface.co/">Hugging Face</a> API for quite sometime and really enjoying the easeness of use - ability to work with different popular transformer models for different types of NLP tasks. And of course, the ability to use several different famous models makes the result almost unbelievable. The <code class="language-plaintext highlighter-rouge">pipeline()</code> - fundamental component in the <em>Transformers</em> library serves as a pipeline between the different steps in an NLP pipeline. For example, we may want to connect a preprocessing step to an analysis step and then to a post-processing step. I believe the ease of use and the availability of several models makes Hugging Face the go-to tool for NLP.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>
</code></pre></div></div>

<p>When instantiating, the <code class="language-plaintext highlighter-rouge">pipeline()</code> expects the user to provide the NLP task we are interested in performing as well as an optional model (when not provided, a default model is used).</p>

<p>We can create, for example, a sentiment analyzer by providing <code class="language-plaintext highlighter-rouge">sentiment-analysis</code> as the task. If we do not specify a model to be used, it defaults to Distilbert model.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sanalyzer</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s">'sentiment-analysis'</span><span class="p">)</span>
</code></pre></div></div>

<p>We can pass strings that we want to analyze the sentiment for.</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sanalyzer</span><span class="p">(</span><span class="s">"I plan to learn"</span><span class="p">)</span>
</code></pre></div></div>
<p>and it returns the sentiment and a score of the sentiment.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; [{'label': 'POSITIVE', 'score': 0.9988747239112854}]
</code></pre></div></div>

<p>So “learn” seems to be a positive thing to do. Let’s keep going with this:</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sanalyzer</span><span class="p">(</span><span class="s">"I plan to learn Spanish"</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="p">[{</span><span class="s">'label'</span><span class="p">:</span> <span class="s">'POSITIVE'</span><span class="p">,</span> <span class="s">'score'</span><span class="p">:</span> <span class="mf">0.9941837191581726</span><span class="p">}]</span>
</code></pre></div></div>

<p>So, learning Spanish also seems to be a positive thing to do. However,</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sanalyzer</span><span class="p">(</span><span class="s">"I plan to learn some more Spanish."</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="p">[{</span><span class="s">'label'</span><span class="p">:</span> <span class="s">'NEGATIVE'</span><span class="p">,</span> <span class="s">'score'</span><span class="p">:</span> <span class="mf">0.9369450807571411</span><span class="p">}]</span>
</code></pre></div></div>

<p>I am not sure why, but learning some more seems to have a negative connotation (may be “some more” indicates some lacking that one is trying to improve upon?). However, if I add an additional phrase the overall sentiment seems to become positive.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sanalyzer</span><span class="p">(</span><span class="s">"I plan to learn some more Spanish. I want to be able to live and work in Spain."</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="p">[{</span><span class="s">'label'</span><span class="p">:</span> <span class="s">'POSITIVE'</span><span class="p">,</span> <span class="s">'score'</span><span class="p">:</span> <span class="mf">0.9970537424087524</span><span class="p">}]</span>
</code></pre></div></div>

<p>These are just some of the challenges with current NLP systems. The result could be interpreted in several ways and if the training (of which a model is a result of) was done on specific set of (data from a specific culture or a communication pattern), some phrases might get inferred as <code class="language-plaintext highlighter-rouge">NEGATIVE</code> though it would not seem negative to the user of such systems. Another example showing a subtle difference:</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sanalyzer</span><span class="p">(</span><span class="s">"I plan to learn enough Corporate Finance in order to get a great job"</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="p">[{</span><span class="s">'label'</span><span class="p">:</span> <span class="s">'NEGATIVE'</span><span class="p">,</span> <span class="s">'score'</span><span class="p">:</span> <span class="mf">0.5767139792442322</span><span class="p">}]</span>
</code></pre></div></div>

<p>returns a <code class="language-plaintext highlighter-rouge">NEGATIVE</code> sentiment while</p>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sanalyzer</span><span class="p">(</span><span class="s">"I plan to learn Corporate Finance in order to get a great job"</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="p">[{</span><span class="s">'label'</span><span class="p">:</span> <span class="s">'POSITIVE'</span><span class="p">,</span> <span class="s">'score'</span><span class="p">:</span> <span class="mf">0.902138888835907</span><span class="p">}]</span>
</code></pre></div></div>
<p>returns a <code class="language-plaintext highlighter-rouge">POSITIVE</code> one:</p>

<p>More intriguing are the expressions that we use depending on cultures and traditions. In many languages, we use different pronouns and verb conjugations depending on if we are talking to elders using a formal language or talking to friends or children (informal language) - like <em>vous</em> vs <em>tu</em> in French, <em>aap</em> vs <em>tum</em> in Hindi, <em>avar</em> vs <em>avan</em> in Tamil, <em>iyaal</em> vs <em>ival</em> in Malayalam, etc. Humans have learnt to make that judgement call even when we talk over the phone - we choose formal or informal language depending on how much respect or importance we attach to the person we are talking to, even if it is a stranger and we are speaking to them for the first time. However, NLP systems do not have that context explicitly encoded and it is difficult to implicitly encode them as some languages do not have such differences and while translating from such languages, one would have to possibly over-correct.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">en_fr_translator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s">"translation_en_to_fr"</span><span class="p">)</span>
<span class="n">en_fr_translator</span><span class="p">(</span><span class="s">"Would you like some coffee?"</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="p">[{</span><span class="s">'translation_text'</span><span class="p">:</span> <span class="s">'Avez-vous envie de prendre du café ?'</span><span class="p">}]</span>
</code></pre></div></div>

<p>As we see, we could offer coffee to a close friend (informal language) or we could be a barista offering coffee to a stranger or a customer (using formal language). These are very difficult to encode implicitly. Even when there are some clues in the statement, like the following sentence which talks about <em>balloons</em> which most likely only children would be interested in, most systems would prefer a formal language in order to be absolutely correct.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">en_fr_translator</span><span class="p">(</span><span class="s">"Do you want a balloon?"</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="p">[{</span><span class="s">'translation_text'</span><span class="p">:</span> <span class="s">'Voulez-vous un ballon?'</span><span class="p">}]</span>
</code></pre></div></div>

<p>There are also everyday language (colloquial) that differs from a more grammatically correct business or literary language. At times, the differences between the two is so large that chatbots may sound weird. Let us contrast English-French translation with French-English translation to check this.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">en_fr_translator</span><span class="p">(</span><span class="s">"There's no one here."</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="p">[{</span><span class="s">'translation_text'</span><span class="p">:</span> <span class="s">"Il n'y a personne ici."</span><span class="p">}]</span>
</code></pre></div></div>

<p>In spoken French, <a href="https://qr.ae/pvKYf3">one usually leaves out the negation (<em>ne</em>) in certain cases</a> and so “<em>Il y a personne ici.</em>” would also actually mean “<em>There’s no one here.</em>”</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fr_en_translator</span><span class="p">(</span><span class="s">"Il y a personne ici."</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="p">[{</span><span class="s">'translation_text'</span><span class="p">:</span> <span class="s">"There's no one here."</span><span class="p">}]</span>
</code></pre></div></div>

<p>Another example, which might sound very counter-intuitive for people new to the French language.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">en_fr_translator</span><span class="p">(</span><span class="s">"I have"</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="p">[{</span><span class="s">'translation_text'</span><span class="p">:</span> <span class="s">"J'ai"</span><span class="p">}]</span>
<span class="n">en_fr_translator</span><span class="p">(</span><span class="s">"more bread."</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="p">[{</span><span class="s">'translation_text'</span><span class="p">:</span> <span class="s">'plus de pain.'</span><span class="p">}]</span>
</code></pre></div></div>

<p>Such statements are not always compositional.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fr_en_translator</span><span class="p">(</span><span class="s">"J'ai plus de pain."</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="p">[{</span><span class="s">'translation_text'</span><span class="p">:</span> <span class="s">"I don't have any more bread."</span><span class="p">}]</span>
</code></pre></div></div>

<p>Many NLP systems are trained on formal and informal phrases and hence would be great translators, they may not always be a great teacher. The fluidity of languages makes languages evolve, creating new words, phrases, letting go some rules of grammar and these are exactly what make languages beatiful and a treasure trove for linguists. These are also the same challenges that make NLP a fascinating subject for Computer Scientists. I am eagerly looking forward to understanding the research in this area hoping that there would be some architecture that would enable us encode some of these connotations implicitly, making NLP systems crawl a little closer towards human-like spoken languages.</p>


        </div>
        
      </li>
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            <a class="post-link" href="/2021/12/21/year-in-formula-one/">The Year in Formula One &rarr;</a>
          </h1>

          <p class="post-meta">Dec 21, 2021 • 
  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/formula-one/">formula one</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/data-science/">data science</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/python/">python</a>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

</p>
        </header>

        <div class="post-content">
          <p>If you are someone who has been watching Formula One over the last decade, it would be safe to bet that you agree 2021 has been one of the exciting year in the sport. Lots of uncertainity, lots of controversies, new, young and energetic racers, and a super-busy calendar with 22 races. In this post, we will look at the last decade in the sport while doing so using Python and Pandas to analyze, plot and visualize the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">constr_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'driver_standings_2010_2021.csv'</span><span class="p">)</span>
<span class="n">driver_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'f1_2010_2021.csv'</span><span class="p">)</span>
</code></pre></div></div>

<p>If we look at the total points by different teams:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">team_totals</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">constr_df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'team'</span><span class="p">])[</span><span class="s">'points'</span><span class="p">]</span>
                           <span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
                           <span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
                           <span class="p">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'team'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'points'</span><span class="p">,</span> 
                 <span class="n">data</span><span class="o">=</span><span class="n">team_totals</span><span class="p">)</span> 
<span class="p">...</span>
</code></pre></div></div>

<p><br /></p>
<div class="img_container">
  <center><img src="https://raw.githubusercontent.com/dotkay/data_science/master/plots/f1_constr_2010_2021.png" /></center>
</div>

<p>Mercedes is clearly the front runner, most of it contributed by Lewis Hamilton as we will see very soon. Having lived in Italy and a Ferrari Fan, it is sad to see Ferrari in second place and even more sad to see the downward trend for the prancing horse.</p>

<p>Let’s turn to the drivers who play a key role in making the sport what it is. After Mike Schumacher’s retirement, there was some competition between Sebastian Vettel and Lewis Hamilton and to some extent Fernando Alonso and Nico Rosberg. Unfortunately Sebastian Vettel’s dominance faded away and Lewis Hamilton started dominating every race. Very soon there was a new kid in the block - <em>Max Verstappen</em>. Young, energetic and impatient, Max Verstappen, racing for RedBull, quickly started dominating the sport throwing a big challenge to Lewis Hamilton. Many predicted his dominance given the last couple of years and if there was even the slightest of doubts, the 2021 racing season would have cleared those away. Just before the last race, Lewis Hamilton and Max Verstappen were tied on the same number of points which shows the sheer scale of the competition.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">driver_totals</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">driver_df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'full_name'</span><span class="p">])[</span><span class="s">'points'</span><span class="p">]</span>
                             <span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
                             <span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
                             <span class="p">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'full_name'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'points'</span><span class="p">,</span> 
            <span class="n">data</span><span class="o">=</span><span class="n">driver_totals</span><span class="p">)</span>
<span class="p">...</span>
</code></pre></div></div>

<p><br /></p>
<div class="img_container">
  <center><img src="https://raw.githubusercontent.com/dotkay/data_science/master/plots/f1_drivers_2010_2021.png" /></center>
</div>

<p>We can also see the maximum points scored by the drivers in any year. This shows Lewis Hamilton dominating the races that were once dominated by Sebastian Vettel.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">max_pt_drivers</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">driver_df</span><span class="p">[</span><span class="n">driver_df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'year'</span><span class="p">])[</span><span class="s">'points'</span><span class="p">]</span>
                              <span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="s">'max'</span><span class="p">)</span> <span class="o">==</span> <span class="n">driver_df</span><span class="p">[</span><span class="s">'points'</span><span class="p">]])</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'year'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'points'</span><span class="p">,</span> 
                 <span class="n">data</span><span class="o">=</span><span class="n">max_pt_drivers</span><span class="p">,</span> 
                 <span class="n">palette</span><span class="o">=</span><span class="s">'crest'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">txt</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ax</span><span class="p">.</span><span class="n">patches</span><span class="p">,</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">max_pt_drivers</span><span class="p">[</span><span class="s">'name'</span><span class="p">])):</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">txt</span><span class="p">,</span> 
                <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">p</span><span class="p">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">p</span><span class="p">.</span><span class="n">get_height</span><span class="p">()),</span>
                <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">textcoords</span><span class="o">=</span><span class="s">'offset points'</span><span class="p">,</span>
                <span class="n">ha</span><span class="o">=</span><span class="s">'center'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s">'center'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span>
               <span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">ax</span><span class="p">.</span><span class="n">get_xticklabels</span><span class="p">(),</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">);</span>
<span class="p">...</span>
</code></pre></div></div>

<p><br /></p>
<div class="img_container">
  <center><img src="https://raw.githubusercontent.com/dotkay/data_science/master/plots/f1_driver_max_pts_2010_2021.png" /></center>
</div>

<p>We can also see which countries have scored the most points. Traditionally, Formula One has been more popular in Europe than the rest of the world. There are and were South American champions but not many of them. I believe this might be due to the cost involved in the sport and few can afford it. Further most of the best automobile makers are from Europe (and few from Japan as well). We can attempt to draw a tree map using <code class="language-plaintext highlighter-rouge">squarify</code> in Python.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">squarify</span>
<span class="n">country_wins</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">driver_df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'nationality'</span><span class="p">])[</span><span class="s">'points'</span><span class="p">]</span>
                            <span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
                            <span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
                            <span class="p">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="n">squarify</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sizes</span><span class="o">=</span><span class="n">country_wins</span><span class="p">[</span><span class="s">'points'</span><span class="p">][:</span><span class="mi">21</span><span class="p">],</span> 
              <span class="n">label</span><span class="o">=</span><span class="n">country_wins</span><span class="p">[</span><span class="s">'nationality'</span><span class="p">][:</span><span class="mi">21</span><span class="p">],</span>
              <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>
<div class="img_container">
  <center><img src="https://raw.githubusercontent.com/dotkay/data_science/master/plots/f1_country_wins_tree.png" /></center>
</div>

<p>If the tree map makes you think GER (Germany) and GBR (Great Britain) are equal, here is a bar chart showing the actual points.</p>

<p><br /></p>
<div class="img_container">
  <center><img src="https://raw.githubusercontent.com/dotkay/data_science/master/plots/f1_country_wins_bar.png" /></center>
</div>

<p>In all, 2021 was a fantastic year for Formula One. I wish the most crucial and deciding race had not ended in a controversial way. Sergio Perez played the best team-mate and tons of thanks to Lewis and Max for the entertainment.</p>

<p>Looking forward to more competition in 2022.</p>

<p><span style="font-size: 70%">
<i>The data is from a Kaggle dataset revised with the last race results of 2021, and the plots were done using matplotlib, seaborn.</i>
</span></p>

        </div>
        
      </li>
    
  </ul>

  
  <div class="pagination">
    
      <a class="previous" href="/posts/3/">&laquo; Older</a>
    

    
      <a class="next" href="/">Newer &raquo;</a>
    
  </div>



</div>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <p>
      

&copy;  - Powered by <a href="https://jekyllrb.com">Jekyll</a> &amp; <a href="https://github.com/yous/whiteglass">whiteglass</a> - Subscribe via <a href="https://dotkay.github.io/feed.xml">RSS</a>

    </p>

  </div>

</footer>


  </body>

</html>
